// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// Bindings for `src/tensorflow_lite/c_api.h`.
///
/// Regenerate bindings with `flutter pub run ffigen --config ffigen_tensorflow_lite.yaml`.
///
class TensorFlowLiteBindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
  _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  TensorFlowLiteBindings(ffi.DynamicLibrary dynamicLibrary)
    : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  TensorFlowLiteBindings.fromLookup(
    ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName) lookup,
  ) : _lookup = lookup;

  /// Returns a new TfLiteOperator instance.
  ///
  /// The returned TfLiteOperator instance represents a definition
  /// of an operator with the identity (builtin_code/custom_name and
  /// version) specified by the parameters, but with all callbacks initially
  /// unset.
  ///
  /// Evaluation of any operation using this operator will be done using
  /// the "prepare" and "invoke" callbacks, which can be set using
  /// `TfLiteOperatorSetPrepare` and
  /// `TfLiteOperatorSetInvoke`, or for async execution
  /// the "prepare", "eval", and "wait" callbacks of the `TfLiteAsyncKernel`,
  /// which can be set using `TfLiteOperatorSetAsyncKernel`.
  /// If the relevant callbacks are not set, then such evaluation will result
  /// in an error status.  So normally any use of this function should be followed
  /// by appropriate calls to set those callbacks.
  ///
  /// \note The caller retains ownership and should ensure that
  /// the lifetime of the `TfLiteOperator` must be at least as long as
  /// the lifetime of any `TfLiteInterpreter` or `tflite::Interpreter` that it is
  /// used in.
  ///
  /// \param builtin_code Enumeration code specifying which builtin operator this
  /// defines, or `TfLiteBuiltinCustom` to define a custom op.
  /// \param custom_name  Name of the custom op, or `nullptr` for a builtin op.
  /// If `custom_name` is non-null, then `builtin_code` should
  /// be `TfLiteBuiltinCustom`.
  /// \param version      Version of the op.  See
  /// https://www.tensorflow.org/lite/guide/ops_version
  /// \param user_data    Opaque pointer passed to the operator's callbacks set
  /// with functions such as `TfLiteOperatorSetXXXWithData`.
  /// The user is expected to manage the memory pointed by
  /// this field and the lifetime of that memory should extend
  /// at least from the call to `TfLiteOperatorCreate`
  /// to the invocation of the callback set with
  /// `TfLiteOperatorSetFreeWithData`.
  ///
  /// \return a newly created TfLiteOperator on success, or a nullptr on failure
  ffi.Pointer<TfLiteOperator> TfLiteOperatorCreate(
    int builtin_code,
    ffi.Pointer<ffi.Char> custom_name,
    int version,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteOperatorCreate(builtin_code, custom_name, version, user_data);
  }

  late final _TfLiteOperatorCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteOperator> Function(
            ffi.Int32,
            ffi.Pointer<ffi.Char>,
            ffi.Int,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteOperatorCreate');
  late final _TfLiteOperatorCreate =
      _TfLiteOperatorCreatePtr.asFunction<
        ffi.Pointer<TfLiteOperator> Function(
          int,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Destroys the TfLiteOperator instance.
  void TfLiteOperatorDelete(ffi.Pointer<TfLiteOperator> registration) {
    return _TfLiteOperatorDelete(registration);
  }

  late final _TfLiteOperatorDeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteOperator>)>
      >('TfLiteOperatorDelete');
  late final _TfLiteOperatorDelete =
      _TfLiteOperatorDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteOperator>)
      >();

  /// Return the builtin op code of the provided external 'registration'.
  int TfLiteOperatorGetBuiltInCode(ffi.Pointer<TfLiteOperator> registration) {
    return _TfLiteOperatorGetBuiltInCode(registration);
  }

  late final _TfLiteOperatorGetBuiltInCodePtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteOperator>)>
      >('TfLiteOperatorGetBuiltInCode');
  late final _TfLiteOperatorGetBuiltInCode =
      _TfLiteOperatorGetBuiltInCodePtr.asFunction<
        int Function(ffi.Pointer<TfLiteOperator>)
      >();

  /// Returns the custom name of the provided 'registration'. The returned pointer
  /// will be non-null iff the op is a custom op.
  ffi.Pointer<ffi.Char> TfLiteOperatorGetCustomName(
    ffi.Pointer<TfLiteOperator> registration,
  ) {
    return _TfLiteOperatorGetCustomName(registration);
  }

  late final _TfLiteOperatorGetCustomNamePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteOperator>)
        >
      >('TfLiteOperatorGetCustomName');
  late final _TfLiteOperatorGetCustomName =
      _TfLiteOperatorGetCustomNamePtr.asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteOperator>)
      >();

  /// Return the OP version of the provided external 'registration'.  Return -1
  /// in case of error, or if the provided address is null.
  int TfLiteOperatorGetVersion(ffi.Pointer<TfLiteOperator> registration) {
    return _TfLiteOperatorGetVersion(registration);
  }

  late final _TfLiteOperatorGetVersionPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int Function(ffi.Pointer<TfLiteOperator>)>
      >('TfLiteOperatorGetVersion');
  late final _TfLiteOperatorGetVersion =
      _TfLiteOperatorGetVersionPtr.asFunction<
        int Function(ffi.Pointer<TfLiteOperator>)
      >();

  /// Return the user data field of the provided external 'registration', or
  /// nullptr if none was set.
  ffi.Pointer<ffi.Void> TfLiteOperatorGetUserData(
    ffi.Pointer<TfLiteOperator> registration,
  ) {
    return _TfLiteOperatorGetUserData(registration);
  }

  late final _TfLiteOperatorGetUserDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteOperator>)
        >
      >('TfLiteOperatorGetUserData');
  late final _TfLiteOperatorGetUserData =
      _TfLiteOperatorGetUserDataPtr.asFunction<
        ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteOperator>)
      >();

  /// Sets the initialization callback for the registration.
  ///
  /// The callback is called to initialize the op from serialized data.
  /// Please refer `init` of `TfLiteRegistration` for the detail.
  ///
  /// Deprecated: Use `TfLiteOperatorSetInitWithData`
  void TfLiteOperatorSetInit(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<ffi.Char> buffer,
          ffi.Size length,
        )
      >
    >
    init,
  ) {
    return _TfLiteOperatorSetInit(registration, init);
  }

  late final _TfLiteOperatorSetInitPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<ffi.Char> buffer,
                  ffi.Size length,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetInit');
  late final _TfLiteOperatorSetInit =
      _TfLiteOperatorSetInitPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<ffi.Char> buffer,
                ffi.Size length,
              )
            >
          >,
        )
      >();

  /// Sets the initialization callback for the registration. The function returns
  /// an error upon failure.
  ///
  /// The callback is called to initialize the op from serialized data. The value
  /// passed in the `user_data` parameter is the value that was passed to
  /// `TfLiteOperatorCreate`.  Please refer `init` of `TfLiteRegistration`
  /// for the detail.
  int TfLiteOperatorSetInitWithData(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<ffi.Char> buffer,
          ffi.Size length,
        )
      >
    >
    init,
  ) {
    return _TfLiteOperatorSetInitWithData(registration, init);
  }

  late final _TfLiteOperatorSetInitWithDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<ffi.Char> buffer,
                  ffi.Size length,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetInitWithData');
  late final _TfLiteOperatorSetInitWithData =
      _TfLiteOperatorSetInitWithDataPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<ffi.Char> buffer,
                ffi.Size length,
              )
            >
          >,
        )
      >();

  /// Sets the deallocation callback for the registration.
  ///
  /// This callback is called to deallocate the data returned by the init
  /// callback. The value passed in the `data` parameter is the value that was
  /// returned by the `init` callback. Please refer `free` of `TfLiteRegistration`
  /// for the detail.
  ///
  /// Deprecated: Use `TfLiteOperatorSetFreeWithData`
  void TfLiteOperatorSetFree(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<ffi.Void> data,
        )
      >
    >
    free,
  ) {
    return _TfLiteOperatorSetFree(registration, free);
  }

  late final _TfLiteOperatorSetFreePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Void Function(
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<ffi.Void> data,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetFree');
  late final _TfLiteOperatorSetFree =
      _TfLiteOperatorSetFreePtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<ffi.Void> data,
              )
            >
          >,
        )
      >();

  /// Sets the deallocation callback for the registration, similarly to
  /// `TfLiteOperatorSetFree`. The function returns an error upon failure.
  ///
  /// This callback is called to deallocate the data returned by the init
  /// callback. The value passed in the `data` parameter is the value that was
  /// returned by the `init` callback. The value passed in the `user_data`
  /// parameter is the value that was passed to `TfLiteOperatorCreate`.
  /// Please refer `free` of `TfLiteRegistration` for the detail.
  int TfLiteOperatorSetFreeWithData(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<ffi.Void> data,
        )
      >
    >
    free,
  ) {
    return _TfLiteOperatorSetFreeWithData(registration, free);
  }

  late final _TfLiteOperatorSetFreeWithDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Void Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<ffi.Void> data,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetFreeWithData');
  late final _TfLiteOperatorSetFreeWithData =
      _TfLiteOperatorSetFreeWithDataPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<ffi.Void> data,
              )
            >
          >,
        )
      >();

  /// Sets the preparation callback for the registration.
  ///
  /// The callback is called when the inputs of operator have been resized.
  /// Please refer `prepare` of `TfLiteRegistration` for the detail.
  ///
  /// Deprecated: Use `TfLiteOperatorSetPrepareWithData`
  void TfLiteOperatorSetPrepare(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Int32 Function(
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    prepare,
  ) {
    return _TfLiteOperatorSetPrepare(registration, prepare);
  }

  late final _TfLiteOperatorSetPreparePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Int32 Function(
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetPrepare');
  late final _TfLiteOperatorSetPrepare =
      _TfLiteOperatorSetPreparePtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Int32 Function(
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the preparation callback for the registration. The function returns an
  /// error upon failure.
  ///
  /// The callback is called when the inputs of operator have been resized.  The
  /// value passed in the `user_data` parameter is the value that was passed to
  /// `TfLiteOperatorCreate`.  Please refer `prepare` of
  /// `TfLiteRegistration` for the detail.
  int TfLiteOperatorSetPrepareWithData(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Int32 Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    prepare,
  ) {
    return _TfLiteOperatorSetPrepareWithData(registration, prepare);
  }

  late final _TfLiteOperatorSetPrepareWithDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Int32 Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetPrepareWithData');
  late final _TfLiteOperatorSetPrepareWithData =
      _TfLiteOperatorSetPrepareWithDataPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Int32 Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the invocation callback for the registration.
  ///
  /// The callback is called when the operator is executed.
  /// Please refer `invoke` of `TfLiteRegistration` for the detail.
  ///
  /// Deprecated: Use `TfLiteOperatorSetInvokeWithData`
  void TfLiteOperatorSetInvoke(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Int32 Function(
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    invoke,
  ) {
    return _TfLiteOperatorSetInvoke(registration, invoke);
  }

  late final _TfLiteOperatorSetInvokePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Int32 Function(
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetInvoke');
  late final _TfLiteOperatorSetInvoke =
      _TfLiteOperatorSetInvokePtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Int32 Function(
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the invocation callback for the registration. The function returns an
  /// error upon failure.
  ///
  /// The callback is called when the operator is executed.  The value passed in
  /// the `user_data` parameter is the value that was passed to
  /// `TfLiteOperatorCreate`.  Please refer `invoke` of `TfLiteRegistration` for
  /// the detail.
  int TfLiteOperatorSetInvokeWithData(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Int32 Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    invoke,
  ) {
    return _TfLiteOperatorSetInvokeWithData(registration, invoke);
  }

  late final _TfLiteOperatorSetInvokeWithDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Int32 Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetInvokeWithData');
  late final _TfLiteOperatorSetInvokeWithData =
      _TfLiteOperatorSetInvokeWithDataPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Int32 Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the async kernel accessor callback for the registration.
  ///
  /// The callback is called to retrieve the async kernel if the delegate supports
  /// it. If the delegate does not support async execution, either this function
  /// should not be called, or `async_kernel` needs to be nullptr.
  /// `node` is the delegate TfLiteNode created by `ModifyGraphWithDelegate`.
  /// Please refer `async_kernel` of `TfLiteRegistration` for the detail.
  ///
  /// \warning This is an experimental API and subject to change.
  /// Deprecated: Use `TfLiteOperatorSetAsyncKernelWithData`
  void TfLiteOperatorSetAsyncKernel(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteAsyncKernel> Function(
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    async_kernel,
  ) {
    return _TfLiteOperatorSetAsyncKernel(registration, async_kernel);
  }

  late final _TfLiteOperatorSetAsyncKernelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteAsyncKernel> Function(
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetAsyncKernel');
  late final _TfLiteOperatorSetAsyncKernel =
      _TfLiteOperatorSetAsyncKernelPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteAsyncKernel> Function(
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the async kernel accessor callback for the registration. The function
  /// returns an error upon failure.
  ///
  /// The callback is called to retrieve the async kernel if the delegate supports
  /// it. If the delegate does not support async execution, either this function
  /// should not be called, or `async_kernel` needs to be nullptr.  `node` is the
  /// delegate TfLiteNode created by `ModifyGraphWithDelegate`.  The value passed
  /// in the `user_data` parameter is the value that was passed to
  /// `TfLiteOperatorCreate`.  Please refer `async_kernel` of `TfLiteRegistration`
  /// for the detail.
  ///
  /// \warning This is an experimental API and subject to change.
  int TfLiteOperatorSetAsyncKernelWithData(
    ffi.Pointer<TfLiteOperator> registration,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteAsyncKernel> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<TfLiteOpaqueContext> context,
          ffi.Pointer<TfLiteOpaqueNode> node,
        )
      >
    >
    async_kernel,
  ) {
    return _TfLiteOperatorSetAsyncKernelWithData(registration, async_kernel);
  }

  late final _TfLiteOperatorSetAsyncKernelWithDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteOperator>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteAsyncKernel> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<TfLiteOpaqueContext> context,
                  ffi.Pointer<TfLiteOpaqueNode> node,
                )
              >
            >,
          )
        >
      >('TfLiteOperatorSetAsyncKernelWithData');
  late final _TfLiteOperatorSetAsyncKernelWithData =
      _TfLiteOperatorSetAsyncKernelWithDataPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteOperator>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteAsyncKernel> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<TfLiteOpaqueContext> context,
                ffi.Pointer<TfLiteOpaqueNode> node,
              )
            >
          >,
        )
      >();

  /// Sets the inplace_operator field of the external registration.
  ///
  /// This is a bitmask. Please refer to `inplace_operator` field of
  /// `TfLiteRegistration` for details.
  void TfLiteOperatorSetInplaceOperator(
    ffi.Pointer<TfLiteOperator> registration,
    int inplace_operator,
  ) {
    return _TfLiteOperatorSetInplaceOperator(registration, inplace_operator);
  }

  late final _TfLiteOperatorSetInplaceOperatorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteOperator>, ffi.Uint64)
        >
      >('TfLiteOperatorSetInplaceOperator');
  late final _TfLiteOperatorSetInplaceOperator =
      _TfLiteOperatorSetInplaceOperatorPtr.asFunction<
        void Function(ffi.Pointer<TfLiteOperator>, int)
      >();

  /// --------------------------------------------------------------------------
  /// The TensorFlow Lite Runtime version.
  ///
  /// Returns a pointer to a statically allocated string that is the version
  /// number of the (potentially dynamically loaded) TF Lite Runtime library.
  /// TensorFlow Lite uses semantic versioning, and the return value should be
  /// in semver 2 format <http://semver.org>, starting with MAJOR.MINOR.PATCH,
  /// e.g. "2.12.0" or "2.13.0-rc2".
  ffi.Pointer<ffi.Char> TfLiteVersion() {
    return _TfLiteVersion();
  }

  late final _TfLiteVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'TfLiteVersion',
      );
  late final _TfLiteVersion =
      _TfLiteVersionPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// --------------------------------------------------------------------------
  /// The TensorFlow Lite Extension APIs version.
  ///
  /// Returns a pointer to a statically allocated string that is the version
  /// number of the TF Lite Extension APIs supported by the (potentially
  /// dynamically loaded) TF Lite Runtime library.  The TF Lite "Extension APIs"
  /// are the APIs for extending TF Lite with custom ops and delegates.
  /// More specifically, this version number covers the (non-experimental)
  /// functionality documented in the following header files:
  ///
  /// * lite/c/c_api_opaque.h
  /// * lite/c/common.h
  /// * lite/c/builtin_op_data.h
  /// * lite/builtin_ops.h
  ///
  /// This version number uses semantic versioning, and the return value should
  /// be in semver 2 format <http://semver.org>, starting with MAJOR.MINOR.PATCH,
  /// e.g. "2.14.0" or "2.15.0-rc2".
  ffi.Pointer<ffi.Char> TfLiteExtensionApisVersion() {
    return _TfLiteExtensionApisVersion();
  }

  late final _TfLiteExtensionApisVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'TfLiteExtensionApisVersion',
      );
  late final _TfLiteExtensionApisVersion =
      _TfLiteExtensionApisVersionPtr.asFunction<
        ffi.Pointer<ffi.Char> Function()
      >();

  /// The supported TensorFlow Lite model file Schema version.
  ///
  /// Returns the (major) version number of the Schema used for model
  /// files that is supported by the (potentially dynamically loaded)
  /// TensorFlow Lite Runtime.
  ///
  /// Model files using schema versions different to this may not be supported by
  /// the current version of the TF Lite Runtime.
  int TfLiteSchemaVersion() {
    return _TfLiteSchemaVersion();
  }

  late final _TfLiteSchemaVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('TfLiteSchemaVersion');
  late final _TfLiteSchemaVersion =
      _TfLiteSchemaVersionPtr.asFunction<int Function()>();

  /// Returns a model from the provided buffer, or null on failure.
  ///
  /// \note The caller retains ownership of the `model_data` buffer and should
  /// ensure that the lifetime of the `model_data` buffer must be at least as long
  /// as the lifetime of the `TfLiteModel` and of any `TfLiteInterpreter` objects
  /// created from that `TfLiteModel`, and furthermore the contents of the
  /// `model_data` buffer must not be modified during that time."
  ffi.Pointer<TfLiteModel> TfLiteModelCreate(
    ffi.Pointer<ffi.Void> model_data,
    int model_size,
  ) {
    return _TfLiteModelCreate(model_data, model_size);
  }

  late final _TfLiteModelCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Void>, ffi.Size)
        >
      >('TfLiteModelCreate');
  late final _TfLiteModelCreate =
      _TfLiteModelCreatePtr.asFunction<
        ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Void>, int)
      >();

  /// Same as `TfLiteModelCreate` with customizble error reporter.
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateWithErrorReporter(
    ffi.Pointer<ffi.Void> model_data,
    int model_size,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> format,
          va_list args,
        )
      >
    >
    reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteModelCreateWithErrorReporter(
      model_data,
      model_size,
      reporter,
      user_data,
    );
  }

  late final _TfLiteModelCreateWithErrorReporterPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Size,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Void Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> format,
                  va_list args,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteModelCreateWithErrorReporter');
  late final _TfLiteModelCreateWithErrorReporter =
      _TfLiteModelCreateWithErrorReporterPtr.asFunction<
        ffi.Pointer<TfLiteModel> Function(
          ffi.Pointer<ffi.Void>,
          int,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> format,
                va_list args,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Returns a model from the provided file, or null on failure.
  ///
  /// \note The file's contents must not be modified during the lifetime of the
  /// `TfLiteModel` or of any `TfLiteInterpreter` objects created from that
  /// `TfLiteModel`.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateFromFile(
    ffi.Pointer<ffi.Char> model_path,
  ) {
    return _TfLiteModelCreateFromFile(model_path);
  }

  late final _TfLiteModelCreateFromFilePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Char>)
        >
      >('TfLiteModelCreateFromFile');
  late final _TfLiteModelCreateFromFile =
      _TfLiteModelCreateFromFilePtr.asFunction<
        ffi.Pointer<TfLiteModel> Function(ffi.Pointer<ffi.Char>)
      >();

  /// Same as `TfLiteModelCreateFromFile` with customizble error reporter.
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  ffi.Pointer<TfLiteModel> TfLiteModelCreateFromFileWithErrorReporter(
    ffi.Pointer<ffi.Char> model_path,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> format,
          va_list args,
        )
      >
    >
    reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteModelCreateFromFileWithErrorReporter(
      model_path,
      reporter,
      user_data,
    );
  }

  late final _TfLiteModelCreateFromFileWithErrorReporterPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteModel> Function(
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Void Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> format,
                  va_list args,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteModelCreateFromFileWithErrorReporter');
  late final _TfLiteModelCreateFromFileWithErrorReporter =
      _TfLiteModelCreateFromFileWithErrorReporterPtr.asFunction<
        ffi.Pointer<TfLiteModel> Function(
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> format,
                va_list args,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Destroys the model instance.
  ///
  /// If `model` is a null pointer, this function has no effect.
  void TfLiteModelDelete(ffi.Pointer<TfLiteModel> model) {
    return _TfLiteModelDelete(model);
  }

  late final _TfLiteModelDeletePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteModel>)>>(
        'TfLiteModelDelete',
      );
  late final _TfLiteModelDelete =
      _TfLiteModelDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteModel>)
      >();

  /// Returns a new interpreter options instances.
  ffi.Pointer<TfLiteInterpreterOptions> TfLiteInterpreterOptionsCreate() {
    return _TfLiteInterpreterOptionsCreate();
  }

  late final _TfLiteInterpreterOptionsCreatePtr =
      _lookup<
        ffi.NativeFunction<ffi.Pointer<TfLiteInterpreterOptions> Function()>
      >('TfLiteInterpreterOptionsCreate');
  late final _TfLiteInterpreterOptionsCreate =
      _TfLiteInterpreterOptionsCreatePtr.asFunction<
        ffi.Pointer<TfLiteInterpreterOptions> Function()
      >();

  /// Creates and returns a shallow copy of an options object.
  ///
  /// The caller is responsible for calling `TfLiteInterpreterOptionsDelete` to
  /// deallocate the object pointed to by the returned pointer.
  ffi.Pointer<TfLiteInterpreterOptions> TfLiteInterpreterOptionsCopy(
    ffi.Pointer<TfLiteInterpreterOptions> from,
  ) {
    return _TfLiteInterpreterOptionsCopy(from);
  }

  late final _TfLiteInterpreterOptionsCopyPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteInterpreterOptions> Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
          )
        >
      >('TfLiteInterpreterOptionsCopy');
  late final _TfLiteInterpreterOptionsCopy =
      _TfLiteInterpreterOptionsCopyPtr.asFunction<
        ffi.Pointer<TfLiteInterpreterOptions> Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
        )
      >();

  /// Destroys the interpreter options instance.
  ///
  /// If `options` is a null pointer, this function has no effect.
  void TfLiteInterpreterOptionsDelete(
    ffi.Pointer<TfLiteInterpreterOptions> options,
  ) {
    return _TfLiteInterpreterOptionsDelete(options);
  }

  late final _TfLiteInterpreterOptionsDeletePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>)
        >
      >('TfLiteInterpreterOptionsDelete');
  late final _TfLiteInterpreterOptionsDelete =
      _TfLiteInterpreterOptionsDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreterOptions>)
      >();

  /// Sets the number of CPU threads to use for the interpreter.
  void TfLiteInterpreterOptionsSetNumThreads(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    int num_threads,
  ) {
    return _TfLiteInterpreterOptionsSetNumThreads(options, num_threads);
  }

  late final _TfLiteInterpreterOptionsSetNumThreadsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>, ffi.Int32)
        >
      >('TfLiteInterpreterOptionsSetNumThreads');
  late final _TfLiteInterpreterOptionsSetNumThreads =
      _TfLiteInterpreterOptionsSetNumThreadsPtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreterOptions>, int)
      >();

  /// Adds a delegate to be applied during `TfLiteInterpreter` creation.
  ///
  /// If delegate application fails, interpreter creation will also fail with an
  /// associated error logged.
  ///
  /// \note The caller retains ownership of the delegate and should ensure that it
  /// remains valid for the duration of any created interpreter's lifetime.
  ///
  /// If you are NOT using "TensorFlow Lite in Play Services", and NOT building
  /// with `TFLITE_WITH_STABLE_ABI` or `TFLITE_USE_OPAQUE_DELEGATE` macros
  /// enabled, it is possible to pass a `TfLiteDelegate*` rather than a
  /// `TfLiteOpaqueDelegate*` to this function, since in those cases,
  /// `TfLiteOpaqueDelegate` is just a typedef alias for `TfLiteDelegate`.
  /// This is for compatibility with existing source code
  /// and existing delegates.  For new delegates, it is recommended to
  /// use `TfLiteOpaqueDelegate` rather than `TfLiteDelegate`.  (See
  /// `TfLiteOpaqueDelegate` in tensorflow/lite/core/c/c_api_types.h.)
  void TfLiteInterpreterOptionsAddDelegate(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<TfLiteOpaqueDelegate> delegate,
  ) {
    return _TfLiteInterpreterOptionsAddDelegate(options, delegate);
  }

  late final _TfLiteInterpreterOptionsAddDelegatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<TfLiteOpaqueDelegate>,
          )
        >
      >('TfLiteInterpreterOptionsAddDelegate');
  late final _TfLiteInterpreterOptionsAddDelegate =
      _TfLiteInterpreterOptionsAddDelegatePtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<TfLiteOpaqueDelegate>,
        )
      >();

  /// Sets a custom error reporter for interpreter execution.
  ///
  /// * `reporter` takes the provided `user_data` object, as well as a C-style
  /// format string and arg list (see also vprintf).
  /// * `user_data` is optional. If non-null, it is owned by the client and must
  /// remain valid for the duration of the interpreter lifetime.
  void TfLiteInterpreterOptionsSetErrorReporter(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> format,
          va_list args,
        )
      >
    >
    reporter,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _TfLiteInterpreterOptionsSetErrorReporter(
      options,
      reporter,
      user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetErrorReporterPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Void Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> format,
                  va_list args,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetErrorReporter');
  late final _TfLiteInterpreterOptionsSetErrorReporter =
      _TfLiteInterpreterOptionsSetErrorReporterPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> format,
                va_list args,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Adds an op registration to be applied during `TfLiteInterpreter` creation.
  ///
  /// The `TfLiteOperator` object is needed to implement custom op of
  /// TFLite Interpreter via C API. Calling this function ensures that any
  /// `TfLiteInterpreter` created with the specified `options` can execute models
  /// that use the custom operator specified in `registration`.
  /// Please refer https://www.tensorflow.org/lite/guide/ops_custom for custom op
  /// support.
  /// \note The caller retains ownership of the TfLiteOperator object
  /// and should ensure that it remains valid for the duration of any created
  /// interpreter's lifetime.
  /// \warning This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsAddOperator(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<TfLiteOperator> registration,
  ) {
    return _TfLiteInterpreterOptionsAddOperator(options, registration);
  }

  late final _TfLiteInterpreterOptionsAddOperatorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<TfLiteOperator>,
          )
        >
      >('TfLiteInterpreterOptionsAddOperator');
  late final _TfLiteInterpreterOptionsAddOperator =
      _TfLiteInterpreterOptionsAddOperatorPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<TfLiteOperator>,
        )
      >();

  /// Enables users to cancel in-flight invocations with
  /// `TfLiteInterpreterCancel`.
  ///
  /// By default it is disabled and calling to `TfLiteInterpreterCancel` will
  /// return kTfLiteError. See `TfLiteInterpreterCancel`.
  int TfLiteInterpreterOptionsEnableCancellation(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    bool enable,
  ) {
    return _TfLiteInterpreterOptionsEnableCancellation(options, enable);
  }

  late final _TfLiteInterpreterOptionsEnableCancellationPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteInterpreterOptions>, ffi.Bool)
        >
      >('TfLiteInterpreterOptionsEnableCancellation');
  late final _TfLiteInterpreterOptionsEnableCancellation =
      _TfLiteInterpreterOptionsEnableCancellationPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreterOptions>, bool)
      >();

  /// Returns a new interpreter using the provided model and options, or null on
  /// failure.
  ///
  /// * `model` must be a valid model instance. The caller retains ownership of
  /// the object, and may destroy it (via TfLiteModelDelete) immediately after
  /// creating the interpreter.  However, if the TfLiteModel was allocated with
  /// TfLiteModelCreate, then the `model_data` buffer that was passed to
  /// TfLiteModelCreate must outlive the lifetime of the TfLiteInterpreter
  /// object that this function returns, and must not be modified during that
  /// time; and if the TfLiteModel was allocated with TfLiteModelCreateFromFile,
  /// then the contents of the model file must not be modified during the
  /// lifetime of the TfLiteInterpreter object that this function returns.
  /// * `optional_options` may be null. The caller retains ownership of the
  /// object, and can safely destroy it (via TfLiteInterpreterOptionsDelete)
  /// immediately after creating the interpreter.
  ///
  /// \note The client *must* explicitly allocate tensors before attempting to
  /// access input tensor data or invoke the interpreter.
  ffi.Pointer<TfLiteInterpreter> TfLiteInterpreterCreate(
    ffi.Pointer<TfLiteModel> model,
    ffi.Pointer<TfLiteInterpreterOptions> optional_options,
  ) {
    return _TfLiteInterpreterCreate(model, optional_options);
  }

  late final _TfLiteInterpreterCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteInterpreter> Function(
            ffi.Pointer<TfLiteModel>,
            ffi.Pointer<TfLiteInterpreterOptions>,
          )
        >
      >('TfLiteInterpreterCreate');
  late final _TfLiteInterpreterCreate =
      _TfLiteInterpreterCreatePtr.asFunction<
        ffi.Pointer<TfLiteInterpreter> Function(
          ffi.Pointer<TfLiteModel>,
          ffi.Pointer<TfLiteInterpreterOptions>,
        )
      >();

  /// Destroys the interpreter.
  ///
  /// If `interpreter` is a null pointer, this function has no effect.
  void TfLiteInterpreterDelete(ffi.Pointer<TfLiteInterpreter> interpreter) {
    return _TfLiteInterpreterDelete(interpreter);
  }

  late final _TfLiteInterpreterDeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterDelete');
  late final _TfLiteInterpreterDelete =
      _TfLiteInterpreterDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the number of input tensors associated with the model.
  int TfLiteInterpreterGetInputTensorCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetInputTensorCount(interpreter);
  }

  late final _TfLiteInterpreterGetInputTensorCountPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterGetInputTensorCount');
  late final _TfLiteInterpreterGetInputTensorCount =
      _TfLiteInterpreterGetInputTensorCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns a pointer to an array of input tensor indices.  The length of the
  /// array can be obtained via a call to `TfLiteInterpreterGetInputTensorCount`.
  ///
  /// Typically the input tensors associated with an `interpreter` would be set
  /// during the initialization of the `interpreter`, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls
  /// to `SetInputs` on the interpreter invalidate the returned pointer.
  ///
  /// The ownership of the array remains with the TFLite runtime.
  ffi.Pointer<ffi.Int> TfLiteInterpreterInputTensorIndices(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterInputTensorIndices(interpreter);
  }

  late final _TfLiteInterpreterInputTensorIndicesPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)
        >
      >('TfLiteInterpreterInputTensorIndices');
  late final _TfLiteInterpreterInputTensorIndices =
      _TfLiteInterpreterInputTensorIndicesPtr.asFunction<
        ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the tensor associated with the input index.
  /// REQUIRES: 0 <= input_index < TfLiteInterpreterGetInputTensorCount(tensor)
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetInputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int input_index,
  ) {
    return _TfLiteInterpreterGetInputTensor(interpreter, input_index);
  }

  late final _TfLiteInterpreterGetInputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterGetInputTensor');
  late final _TfLiteInterpreterGetInputTensor =
      _TfLiteInterpreterGetInputTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Resizes the specified input tensor.
  ///
  /// \note After a resize, the client *must* explicitly allocate tensors before
  /// attempting to access the resized tensor data or invoke the interpreter.
  ///
  /// REQUIRES: 0 <= input_index < TfLiteInterpreterGetInputTensorCount(tensor)
  ///
  /// This function makes a copy of the input dimensions, so the client can safely
  /// deallocate `input_dims` immediately after this function returns.
  int TfLiteInterpreterResizeInputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int input_index,
    ffi.Pointer<ffi.Int> input_dims,
    int input_dims_size,
  ) {
    return _TfLiteInterpreterResizeInputTensor(
      interpreter,
      input_index,
      input_dims,
      input_dims_size,
    );
  }

  late final _TfLiteInterpreterResizeInputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int32,
            ffi.Pointer<ffi.Int>,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterResizeInputTensor');
  late final _TfLiteInterpreterResizeInputTensor =
      _TfLiteInterpreterResizeInputTensorPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteInterpreter>,
          int,
          ffi.Pointer<ffi.Int>,
          int,
        )
      >();

  /// Updates allocations for all tensors, resizing dependent tensors using the
  /// specified input tensor dimensionality.
  ///
  /// This is a relatively expensive operation, and need only be called after
  /// creating the graph and/or resizing any inputs.
  int TfLiteInterpreterAllocateTensors(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterAllocateTensors(interpreter);
  }

  late final _TfLiteInterpreterAllocateTensorsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterAllocateTensors');
  late final _TfLiteInterpreterAllocateTensors =
      _TfLiteInterpreterAllocateTensorsPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Runs inference for the loaded graph.
  ///
  /// Before calling this function, the caller should first invoke
  /// TfLiteInterpreterAllocateTensors() and should also set the values for the
  /// input tensors.  After successfully calling this function, the values for the
  /// output tensors will be set.
  ///
  /// \note It is possible that the interpreter is not in a ready state to
  /// evaluate (e.g., if AllocateTensors() hasn't been called, or if a
  /// ResizeInputTensor() has been performed without a subsequent call to
  /// AllocateTensors()).
  ///
  /// If the (experimental!) delegate fallback option was enabled in the
  /// interpreter options, then the interpreter will automatically fall back to
  /// not using any delegates if execution with delegates fails. For details,
  /// see TfLiteInterpreterOptionsSetEnableDelegateFallback in
  /// c_api_experimental.h.
  ///
  /// Returns one of the following status codes:
  /// - kTfLiteOk: Success. Output is valid.
  /// - kTfLiteDelegateError: Execution with delegates failed, due to a problem
  /// with the delegate(s). If fallback was not enabled, output is invalid.
  /// If fallback was enabled, this return value indicates that fallback
  /// succeeded, the output is valid, and all delegates previously applied to
  /// the interpreter have been undone.
  /// - kTfLiteApplicationError: Same as for kTfLiteDelegateError, except that
  /// the problem was not with the delegate itself, but rather was
  /// due to an incompatibility between the delegate(s) and the
  /// interpreter or model.
  /// - kTfLiteError: Unexpected/runtime failure. Output is invalid.
  int TfLiteInterpreterInvoke(ffi.Pointer<TfLiteInterpreter> interpreter) {
    return _TfLiteInterpreterInvoke(interpreter);
  }

  late final _TfLiteInterpreterInvokePtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterInvoke');
  late final _TfLiteInterpreterInvoke =
      _TfLiteInterpreterInvokePtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the number of output tensors associated with the model.
  int TfLiteInterpreterGetOutputTensorCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetOutputTensorCount(interpreter);
  }

  late final _TfLiteInterpreterGetOutputTensorCountPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterGetOutputTensorCount');
  late final _TfLiteInterpreterGetOutputTensorCount =
      _TfLiteInterpreterGetOutputTensorCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns a pointer to an array of output tensor indices.  The length of the
  /// array can be obtained via a call to `TfLiteInterpreterGetOutputTensorCount`.
  ///
  /// Typically the output tensors associated with an `interpreter` would be set
  /// during the initialization of the `interpreter`, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls
  /// to `SetOutputs` on the interpreter invalidate the returned pointer.
  ///
  /// The ownership of the array remains with the TFLite runtime.
  ffi.Pointer<ffi.Int> TfLiteInterpreterOutputTensorIndices(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterOutputTensorIndices(interpreter);
  }

  late final _TfLiteInterpreterOutputTensorIndicesPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)
        >
      >('TfLiteInterpreterOutputTensorIndices');
  late final _TfLiteInterpreterOutputTensorIndices =
      _TfLiteInterpreterOutputTensorIndicesPtr.asFunction<
        ffi.Pointer<ffi.Int> Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the tensor associated with the output index.
  /// REQUIRES: 0 <= output_index < TfLiteInterpreterGetOutputTensorCount(tensor)
  ///
  /// \note The shape and underlying data buffer for output tensors may be not
  /// be available until after the output tensor has been both sized and
  /// allocated.
  /// In general, best practice is to interact with the output tensor *after*
  /// calling TfLiteInterpreterInvoke().
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetOutputTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int output_index,
  ) {
    return _TfLiteInterpreterGetOutputTensor(interpreter, output_index);
  }

  late final _TfLiteInterpreterGetOutputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterGetOutputTensor');
  late final _TfLiteInterpreterGetOutputTensor =
      _TfLiteInterpreterGetOutputTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Returns modifiable access to the tensor that corresponds to the
  /// specified `index` and is associated with the provided `interpreter`.
  ///
  /// This requires the `index` to be between 0 and N - 1, where N is the
  /// number of tensors in the model.
  ///
  /// Typically the tensors associated with the `interpreter` would be set during
  /// the `interpreter` initialization, through a mechanism like the
  /// `InterpreterBuilder`, and remain unchanged throughout the lifetime of the
  /// interpreter.  However, there are some circumstances in which the pointer may
  /// not remain valid throughout the lifetime of the interpreter, because calls
  /// to `AddTensors` on the interpreter invalidate the returned pointer.
  ///
  /// Note the difference between this function and
  /// `TfLiteInterpreterGetInputTensor` (or `TfLiteInterpreterGetOutputTensor` for
  /// that matter): `TfLiteInterpreterGetTensor` takes an index into the array of
  /// all tensors associated with the `interpreter`'s model, whereas
  /// `TfLiteInterpreterGetInputTensor` takes an index into the array of input
  /// tensors.
  ///
  /// The ownership of the tensor remains with the TFLite runtime, meaning the
  /// caller should not deallocate the pointer.
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int index,
  ) {
    return _TfLiteInterpreterGetTensor(interpreter, index);
  }

  late final _TfLiteInterpreterGetTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int,
          )
        >
      >('TfLiteInterpreterGetTensor');
  late final _TfLiteInterpreterGetTensor =
      _TfLiteInterpreterGetTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Tries to cancel any in-flight invocation.
  ///
  /// \note This only cancels `TfLiteInterpreterInvoke` calls that happen before
  /// calling this and it does not cancel subsequent invocations.
  /// \note Calling this function will also cancel any in-flight invocations of
  /// SignatureRunners constructed from this interpreter.
  /// Non-blocking and thread safe.
  ///
  /// Returns kTfLiteError if cancellation is not enabled via
  /// `TfLiteInterpreterOptionsEnableCancellation`.
  int TfLiteInterpreterCancel(ffi.Pointer<TfLiteInterpreter> interpreter) {
    return _TfLiteInterpreterCancel(interpreter);
  }

  late final _TfLiteInterpreterCancelPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterCancel');
  late final _TfLiteInterpreterCancel =
      _TfLiteInterpreterCancelPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the number of signatures defined in the model.
  int TfLiteInterpreterGetSignatureCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetSignatureCount(interpreter);
  }

  late final _TfLiteInterpreterGetSignatureCountPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterGetSignatureCount');
  late final _TfLiteInterpreterGetSignatureCount =
      _TfLiteInterpreterGetSignatureCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the key of the Nth signature in the model, where N is specified as
  /// `signature_index`.
  ///
  /// NOTE: The lifetime of the returned key is the same as (and depends on) the
  /// lifetime of `interpreter`.
  ffi.Pointer<ffi.Char> TfLiteInterpreterGetSignatureKey(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int signature_index,
  ) {
    return _TfLiteInterpreterGetSignatureKey(interpreter, signature_index);
  }

  late final _TfLiteInterpreterGetSignatureKeyPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterGetSignatureKey');
  late final _TfLiteInterpreterGetSignatureKey =
      _TfLiteInterpreterGetSignatureKeyPtr.asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Returns a new signature runner using the provided interpreter and signature
  /// key, or nullptr on failure.
  ///
  /// NOTE: `signature_key` is a null-terminated C string that must match the
  /// key of a signature in the interpreter's model.
  ///
  /// NOTE: The returned signature runner should be destroyed, by calling
  /// TfLiteSignatureRunnerDelete(), before the interpreter is destroyed.
  ffi.Pointer<TfLiteSignatureRunner> TfLiteInterpreterGetSignatureRunner(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    ffi.Pointer<ffi.Char> signature_key,
  ) {
    return _TfLiteInterpreterGetSignatureRunner(interpreter, signature_key);
  }

  late final _TfLiteInterpreterGetSignatureRunnerPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteSignatureRunner> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('TfLiteInterpreterGetSignatureRunner');
  late final _TfLiteInterpreterGetSignatureRunner =
      _TfLiteInterpreterGetSignatureRunnerPtr.asFunction<
        ffi.Pointer<TfLiteSignatureRunner> Function(
          ffi.Pointer<TfLiteInterpreter>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  /// Returns the number of inputs associated with a signature.
  int TfLiteSignatureRunnerGetInputCount(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerGetInputCount(signature_runner);
  }

  late final _TfLiteSignatureRunnerGetInputCountPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerGetInputCount');
  late final _TfLiteSignatureRunnerGetInputCount =
      _TfLiteSignatureRunnerGetInputCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// Returns the (null-terminated) name of the Nth input in a signature, where N
  /// is specified as `input_index`.
  ///
  /// NOTE: The lifetime of the returned name is the same as (and depends on) the
  /// lifetime of `signature_runner`.
  ffi.Pointer<ffi.Char> TfLiteSignatureRunnerGetInputName(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
    int input_index,
  ) {
    return _TfLiteSignatureRunnerGetInputName(signature_runner, input_index);
  }

  late final _TfLiteSignatureRunnerGetInputNamePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
            ffi.Pointer<TfLiteSignatureRunner>,
            ffi.Int32,
          )
        >
      >('TfLiteSignatureRunnerGetInputName');
  late final _TfLiteSignatureRunnerGetInputName =
      _TfLiteSignatureRunnerGetInputNamePtr.asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteSignatureRunner>, int)
      >();

  /// Resizes the input tensor identified as `input_name` to be the dimensions
  /// specified by `input_dims` and `input_dims_size`. Only unknown dimensions can
  /// be resized with this function. Unknown dimensions are indicated as `-1` in
  /// the `dims_signature` attribute of a TfLiteTensor.
  ///
  /// Returns status of failure or success. Note that this doesn't actually resize
  /// any existing buffers. A call to TfLiteSignatureRunnerAllocateTensors() is
  /// required to change the tensor input buffer.
  ///
  /// NOTE: This function is similar to TfLiteInterpreterResizeInputTensorStrict()
  /// and not TfLiteInterpreterResizeInputTensor().
  ///
  /// NOTE: `input_name` must match the name of an input in the signature.
  ///
  /// NOTE: This function makes a copy of the input dimensions, so the caller can
  /// safely deallocate `input_dims` immediately after this function returns.
  int TfLiteSignatureRunnerResizeInputTensor(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
    ffi.Pointer<ffi.Char> input_name,
    ffi.Pointer<ffi.Int> input_dims,
    int input_dims_size,
  ) {
    return _TfLiteSignatureRunnerResizeInputTensor(
      signature_runner,
      input_name,
      input_dims,
      input_dims_size,
    );
  }

  late final _TfLiteSignatureRunnerResizeInputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteSignatureRunner>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<ffi.Int>,
            ffi.Int32,
          )
        >
      >('TfLiteSignatureRunnerResizeInputTensor');
  late final _TfLiteSignatureRunnerResizeInputTensor =
      _TfLiteSignatureRunnerResizeInputTensorPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteSignatureRunner>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Int>,
          int,
        )
      >();

  /// Updates allocations for tensors associated with a signature and resizes
  /// dependent tensors using the specified input tensor dimensionality.
  /// This is a relatively expensive operation and hence should only be called
  /// after initializing the signature runner object and/or resizing any inputs.
  int TfLiteSignatureRunnerAllocateTensors(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerAllocateTensors(signature_runner);
  }

  late final _TfLiteSignatureRunnerAllocateTensorsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerAllocateTensors');
  late final _TfLiteSignatureRunnerAllocateTensors =
      _TfLiteSignatureRunnerAllocateTensorsPtr.asFunction<
        int Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// Returns the input tensor identified by `input_name` in the given signature.
  /// Returns nullptr if the given name is not valid.
  ///
  /// NOTE: The lifetime of the returned tensor is the same as (and depends on)
  /// the lifetime of `signature_runner`.
  ffi.Pointer<TfLiteTensor> TfLiteSignatureRunnerGetInputTensor(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
    ffi.Pointer<ffi.Char> input_name,
  ) {
    return _TfLiteSignatureRunnerGetInputTensor(signature_runner, input_name);
  }

  late final _TfLiteSignatureRunnerGetInputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteSignatureRunner>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('TfLiteSignatureRunnerGetInputTensor');
  late final _TfLiteSignatureRunnerGetInputTensor =
      _TfLiteSignatureRunnerGetInputTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(
          ffi.Pointer<TfLiteSignatureRunner>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  /// Runs inference on a given signature.
  ///
  /// Before calling this function, the caller should first invoke
  /// TfLiteSignatureRunnerAllocateTensors() and should also set the values for
  /// the input tensors. After successfully calling this function, the values for
  /// the output tensors will be set.
  int TfLiteSignatureRunnerInvoke(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerInvoke(signature_runner);
  }

  late final _TfLiteSignatureRunnerInvokePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerInvoke');
  late final _TfLiteSignatureRunnerInvoke =
      _TfLiteSignatureRunnerInvokePtr.asFunction<
        int Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// Returns the number of output tensors associated with the signature.
  int TfLiteSignatureRunnerGetOutputCount(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerGetOutputCount(signature_runner);
  }

  late final _TfLiteSignatureRunnerGetOutputCountPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerGetOutputCount');
  late final _TfLiteSignatureRunnerGetOutputCount =
      _TfLiteSignatureRunnerGetOutputCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// Returns the (null-terminated) name of the Nth output in a signature, where
  /// N is specified as `output_index`.
  ///
  /// NOTE: The lifetime of the returned name is the same as (and depends on) the
  /// lifetime of `signature_runner`.
  ffi.Pointer<ffi.Char> TfLiteSignatureRunnerGetOutputName(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
    int output_index,
  ) {
    return _TfLiteSignatureRunnerGetOutputName(signature_runner, output_index);
  }

  late final _TfLiteSignatureRunnerGetOutputNamePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
            ffi.Pointer<TfLiteSignatureRunner>,
            ffi.Int32,
          )
        >
      >('TfLiteSignatureRunnerGetOutputName');
  late final _TfLiteSignatureRunnerGetOutputName =
      _TfLiteSignatureRunnerGetOutputNamePtr.asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteSignatureRunner>, int)
      >();

  /// Returns the output tensor identified by `output_name` in the given
  /// signature. Returns nullptr if the given name is not valid.
  ///
  /// NOTE: The lifetime of the returned tensor is the same as (and depends on)
  /// the lifetime of `signature_runner`.
  ffi.Pointer<TfLiteTensor> TfLiteSignatureRunnerGetOutputTensor(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
    ffi.Pointer<ffi.Char> output_name,
  ) {
    return _TfLiteSignatureRunnerGetOutputTensor(signature_runner, output_name);
  }

  late final _TfLiteSignatureRunnerGetOutputTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteSignatureRunner>,
            ffi.Pointer<ffi.Char>,
          )
        >
      >('TfLiteSignatureRunnerGetOutputTensor');
  late final _TfLiteSignatureRunnerGetOutputTensor =
      _TfLiteSignatureRunnerGetOutputTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(
          ffi.Pointer<TfLiteSignatureRunner>,
          ffi.Pointer<ffi.Char>,
        )
      >();

  /// Returns the type of a tensor element.
  int TfLiteTensorType(ffi.Pointer<TfLiteTensor> tensor) {
    return _TfLiteTensorType(tensor);
  }

  late final _TfLiteTensorTypePtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteTensor>)>
      >('TfLiteTensorType');
  late final _TfLiteTensorType =
      _TfLiteTensorTypePtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Returns the number of dimensions that the tensor has.  Returns -1 in case
  /// the 'opaque_tensor' does not have its dimensions property set.
  int TfLiteTensorNumDims(ffi.Pointer<TfLiteTensor> tensor) {
    return _TfLiteTensorNumDims(tensor);
  }

  late final _TfLiteTensorNumDimsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteTensor>)>
      >('TfLiteTensorNumDims');
  late final _TfLiteTensorNumDims =
      _TfLiteTensorNumDimsPtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Returns the length of the tensor in the "dim_index" dimension.
  /// REQUIRES: 0 <= dim_index < TFLiteTensorNumDims(tensor)
  int TfLiteTensorDim(ffi.Pointer<TfLiteTensor> tensor, int dim_index) {
    return _TfLiteTensorDim(tensor, dim_index);
  }

  late final _TfLiteTensorDimPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteTensor>, ffi.Int32)
        >
      >('TfLiteTensorDim');
  late final _TfLiteTensorDim =
      _TfLiteTensorDimPtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>, int)
      >();

  /// Returns the size of the underlying data in bytes.
  int TfLiteTensorByteSize(ffi.Pointer<TfLiteTensor> tensor) {
    return _TfLiteTensorByteSize(tensor);
  }

  late final _TfLiteTensorByteSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<TfLiteTensor>)>>(
        'TfLiteTensorByteSize',
      );
  late final _TfLiteTensorByteSize =
      _TfLiteTensorByteSizePtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Returns a pointer to the underlying data buffer.
  ///
  /// \note The result may be null if tensors have not yet been allocated, e.g.,
  /// if the Tensor has just been created or resized and `TfLiteAllocateTensors()`
  /// has yet to be called, or if the output tensor is dynamically sized and the
  /// interpreter hasn't been invoked.
  ffi.Pointer<ffi.Void> TfLiteTensorData(ffi.Pointer<TfLiteTensor> tensor) {
    return _TfLiteTensorData(tensor);
  }

  late final _TfLiteTensorDataPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteTensor>)
        >
      >('TfLiteTensorData');
  late final _TfLiteTensorData =
      _TfLiteTensorDataPtr.asFunction<
        ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Returns the (null-terminated) name of the tensor.
  ffi.Pointer<ffi.Char> TfLiteTensorName(ffi.Pointer<TfLiteTensor> tensor) {
    return _TfLiteTensorName(tensor);
  }

  late final _TfLiteTensorNamePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteTensor>)
        >
      >('TfLiteTensorName');
  late final _TfLiteTensorName =
      _TfLiteTensorNamePtr.asFunction<
        ffi.Pointer<ffi.Char> Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Returns the parameters for asymmetric quantization. The quantization
  /// parameters are only valid when the tensor type is `kTfLiteUInt8` and the
  /// `scale != 0`. Quantized values can be converted back to float using:
  /// real_value = scale * (quantized_value - zero_point);
  TfLiteQuantizationParams TfLiteTensorQuantizationParams(
    ffi.Pointer<TfLiteTensor> tensor,
  ) {
    return _TfLiteTensorQuantizationParams(tensor);
  }

  late final _TfLiteTensorQuantizationParamsPtr =
      _lookup<
        ffi.NativeFunction<
          TfLiteQuantizationParams Function(ffi.Pointer<TfLiteTensor>)
        >
      >('TfLiteTensorQuantizationParams');
  late final _TfLiteTensorQuantizationParams =
      _TfLiteTensorQuantizationParamsPtr.asFunction<
        TfLiteQuantizationParams Function(ffi.Pointer<TfLiteTensor>)
      >();

  /// Copies from the provided input buffer into the tensor's buffer.
  /// REQUIRES: input_data_size == TfLiteTensorByteSize(tensor)
  int TfLiteTensorCopyFromBuffer(
    ffi.Pointer<TfLiteTensor> tensor,
    ffi.Pointer<ffi.Void> input_data,
    int input_data_size,
  ) {
    return _TfLiteTensorCopyFromBuffer(tensor, input_data, input_data_size);
  }

  late final _TfLiteTensorCopyFromBufferPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteTensor>,
            ffi.Pointer<ffi.Void>,
            ffi.Size,
          )
        >
      >('TfLiteTensorCopyFromBuffer');
  late final _TfLiteTensorCopyFromBuffer =
      _TfLiteTensorCopyFromBufferPtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>, int)
      >();

  /// Copies to the provided output buffer from the tensor's buffer.
  /// REQUIRES: output_data_size == TfLiteTensorByteSize(tensor)
  int TfLiteTensorCopyToBuffer(
    ffi.Pointer<TfLiteTensor> output_tensor,
    ffi.Pointer<ffi.Void> output_data,
    int output_data_size,
  ) {
    return _TfLiteTensorCopyToBuffer(
      output_tensor,
      output_data,
      output_data_size,
    );
  }

  late final _TfLiteTensorCopyToBufferPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteTensor>,
            ffi.Pointer<ffi.Void>,
            ffi.Size,
          )
        >
      >('TfLiteTensorCopyToBuffer');
  late final _TfLiteTensorCopyToBuffer =
      _TfLiteTensorCopyToBufferPtr.asFunction<
        int Function(ffi.Pointer<TfLiteTensor>, ffi.Pointer<ffi.Void>, int)
      >();

  /// Destroys the signature runner.
  ///
  /// If `signature_runner` is a null pointer, this function has no effect.
  void TfLiteSignatureRunnerDelete(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerDelete(signature_runner);
  }

  late final _TfLiteSignatureRunnerDeletePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerDelete');
  late final _TfLiteSignatureRunnerDelete =
      _TfLiteSignatureRunnerDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// --------------------------------------------------------------------------
  /// Resets all variable tensors to zero.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterResetVariableTensors(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterResetVariableTensors(interpreter);
  }

  late final _TfLiteInterpreterResetVariableTensorsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterResetVariableTensors');
  late final _TfLiteInterpreterResetVariableTensors =
      _TfLiteInterpreterResetVariableTensorsPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the number of variable tensors associated with the model.
  int TfLiteInterpreterGetVariableTensorCount(
    ffi.Pointer<TfLiteInterpreter> interpreter,
  ) {
    return _TfLiteInterpreterGetVariableTensorCount(interpreter);
  }

  late final _TfLiteInterpreterGetVariableTensorCountPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>)>
      >('TfLiteInterpreterGetVariableTensorCount');
  late final _TfLiteInterpreterGetVariableTensorCount =
      _TfLiteInterpreterGetVariableTensorCountPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>)
      >();

  /// Returns the tensor associated with the variable tensor index.
  /// REQUIRES: 0 <= input_index <
  /// TfLiteInterpreterGetVariableTensorCount(interpreter)
  ffi.Pointer<TfLiteTensor> TfLiteInterpreterGetVariableTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int variable_index,
  ) {
    return _TfLiteInterpreterGetVariableTensor(interpreter, variable_index);
  }

  late final _TfLiteInterpreterGetVariableTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteTensor> Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterGetVariableTensor');
  late final _TfLiteInterpreterGetVariableTensor =
      _TfLiteInterpreterGetVariableTensorPtr.asFunction<
        ffi.Pointer<TfLiteTensor> Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Adds an op registration for a builtin operator.
  ///
  /// Op registrations are used to map ops referenced in the flatbuffer model
  /// to executable function pointers (`TfLiteRegistration`s).
  ///
  /// NOTE: The interpreter will make a shallow copy of `registration` internally,
  /// so the caller should ensure that its contents (function pointers, etc...)
  /// remain valid for the duration of the interpreter's lifetime. A common
  /// practice is making the provided `TfLiteRegistration` instance static.
  ///
  /// Code that uses this function should NOT call
  /// `TfLiteInterpreterOptionsSetOpResolver` (or related functions) on the same
  /// options object.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsAddBuiltinOp(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    int op,
    ffi.Pointer<TfLiteRegistration> registration,
    int min_version,
    int max_version,
  ) {
    return _TfLiteInterpreterOptionsAddBuiltinOp(
      options,
      op,
      registration,
      min_version,
      max_version,
    );
  }

  late final _TfLiteInterpreterOptionsAddBuiltinOpPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Int32,
            ffi.Pointer<TfLiteRegistration>,
            ffi.Int32,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterOptionsAddBuiltinOp');
  late final _TfLiteInterpreterOptionsAddBuiltinOp =
      _TfLiteInterpreterOptionsAddBuiltinOpPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          int,
          ffi.Pointer<TfLiteRegistration>,
          int,
          int,
        )
      >();

  /// Adds an op registration for a custom operator.
  ///
  /// Op registrations are used to map ops referenced in the flatbuffer model
  /// to executable function pointers (`TfLiteRegistration`s).
  ///
  /// NOTE: The interpreter will make a shallow copy of `registration` internally,
  /// so the caller should ensure that its contents (function pointers, etc...)
  /// remain valid for the duration of any created interpreter's lifetime. A
  /// common practice is making the provided `TfLiteRegistration` instance static.
  ///
  /// The lifetime of the string pointed to by `name` must be at least as long
  /// as the lifetime of the `TfLiteInterpreterOptions`.
  ///
  /// Code that uses this function should NOT call
  /// `TfLiteInterpreterOptionsSetOpResolver` (or related functions) on the same
  /// options object.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsAddCustomOp(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<TfLiteRegistration> registration,
    int min_version,
    int max_version,
  ) {
    return _TfLiteInterpreterOptionsAddCustomOp(
      options,
      name,
      registration,
      min_version,
      max_version,
    );
  }

  late final _TfLiteInterpreterOptionsAddCustomOpPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<ffi.Char>,
            ffi.Pointer<TfLiteRegistration>,
            ffi.Int32,
            ffi.Int32,
          )
        >
      >('TfLiteInterpreterOptionsAddCustomOp');
  late final _TfLiteInterpreterOptionsAddCustomOp =
      _TfLiteInterpreterOptionsAddCustomOpPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<TfLiteRegistration>,
          int,
          int,
        )
      >();

  /// Registers callbacks for resolving builtin or custom operators.
  ///
  /// The `TfLiteInterpreterOptionsSetOpResolverExternal` function provides an
  /// alternative method for registering builtin ops and/or custom ops, by
  /// providing operator resolver callbacks.  Unlike using
  /// `TfLiteInterpreterOptionsAddOperator`,
  /// `TfLiteInterpreterOptionsAddBuiltinOp` and/or
  /// `TfLiteInterpreterOptionsAddAddCustomOp`, these let you register all the
  /// operators in a single call.
  ///
  /// Code that uses this function should NOT call
  /// `TfLiteInterpreterOptionsAddBuiltin` or
  /// `TfLiteInterpreterOptionsAddCustomOp` on the same options object.
  ///
  /// If `op_resolver_user_data` is non-null, its lifetime must be at least as
  /// long as the lifetime of the `TfLiteInterpreterOptions`.
  ///
  /// The TfLiteOperator objects whose addresses are returned by
  /// `find_builtin_op` and `find_custom_op` must outlive both the
  /// InterpreterOptions object and any Interpreter object created from it.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsSetOpResolverExternal(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteOperator> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteOperator> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> custom_op,
          ffi.Int version,
        )
      >
    >
    find_custom_op,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolverExternal(
      options,
      find_builtin_op,
      find_custom_op,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverExternalPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteOperator> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteOperator> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> custom_op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolverExternal');
  late final _TfLiteInterpreterOptionsSetOpResolverExternal =
      _TfLiteInterpreterOptionsSetOpResolverExternalPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteOperator> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteOperator> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> custom_op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// \private
  /// Registers callbacks for resolving builtin or custom operators.
  ///
  /// This combines the effects of TfLiteInterpreterOptionsSetOpResolverExternal
  /// and TfLiteInterpreterOptionsSetOpResolver.  The callbacks that return
  /// TfLiteOperator will be called first, but if they return a
  /// TfLiteOperator object that has no methods set, then
  /// the callbacks that return a TfLiteRegistration will be called to get
  /// the methods.
  ///
  /// WARNING: This function is experimental and subject to change.
  ///
  /// WARNING: This function is not an official part of the API,
  /// and should not be used by apps.  It is intended for use only from
  /// TF Lite itself.
  void TfLiteInterpreterOptionsSetOpResolverExternalWithFallback(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteOperator> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op_external,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteOperator> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> custom_op,
          ffi.Int version,
        )
      >
    >
    find_custom_op_external,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int32 op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> op,
          ffi.Int version,
        )
      >
    >
    find_custom_op,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolverExternalWithFallback(
      options,
      find_builtin_op_external,
      find_custom_op_external,
      find_builtin_op,
      find_custom_op,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverExternalWithFallbackPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteOperator> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteOperator> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> custom_op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int32 op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolverExternalWithFallback');
  late final _TfLiteInterpreterOptionsSetOpResolverExternalWithFallback =
      _TfLiteInterpreterOptionsSetOpResolverExternalWithFallbackPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteOperator> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteOperator> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> custom_op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int32 op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Registers callbacks for resolving builtin or custom operators.
  ///
  /// The `TfLiteInterpreterOptionsSetOpResolver` function provides an alternative
  /// method for registering builtin ops and/or custom ops, by providing operator
  /// resolver callbacks.  Unlike using `TfLiteInterpreterOptionsAddBuiltinOp`
  /// and/or `TfLiteInterpreterOptionsAddAddCustomOp`, these let you register all
  /// the operators in a single call.
  ///
  /// Code that uses this function should NOT call
  /// `TfLiteInterpreterOptionsAddBuiltin` or
  /// `TfLiteInterpreterOptionsAddCustomOp` on the same options object.
  ///
  /// If `op_resolver_user_data` is non-null, its lifetime must be at least as
  /// long as the lifetime of the `TfLiteInterpreterOptions`.
  ///
  /// WARNING: This is an experimental API and subject to change.
  ///
  /// DEPRECATED: use TfLiteInterpreterOptionsSetOpResolverExternal instead.
  void TfLiteInterpreterOptionsSetOpResolver(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int32 op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> custom_op,
          ffi.Int version,
        )
      >
    >
    find_custom_op,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolver(
      options,
      find_builtin_op,
      find_custom_op,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int32 op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> custom_op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolver');
  late final _TfLiteInterpreterOptionsSetOpResolver =
      _TfLiteInterpreterOptionsSetOpResolverPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int32 op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> custom_op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// \private
  /// Backward-compat version of TfLiteInterpreterOptionsSetOpResolver.
  ///
  /// WARNING: This function is deprecated / not an official part of the API, is
  /// only for binary backwards compatibility, and should not be called.
  void TfLiteInterpreterOptionsSetOpResolverV3(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V3> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int32 op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op_v3,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V3> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> op,
          ffi.Int version,
        )
      >
    >
    find_custom_op_v3,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolverV3(
      options,
      find_builtin_op_v3,
      find_custom_op_v3,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverV3Ptr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V3> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int32 op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V3> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolverV3');
  late final _TfLiteInterpreterOptionsSetOpResolverV3 =
      _TfLiteInterpreterOptionsSetOpResolverV3Ptr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V3> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int32 op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V3> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// \private
  /// Backward-compat version of TfLiteInterpreterOptionsSetOpResolver.
  ///
  /// WARNING: This function is deprecated / not an official part of the API, is
  /// only for binary backwards compatibility, and should not be called.
  void TfLiteInterpreterOptionsSetOpResolverV2(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V2> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int32 op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op_v2,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V2> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> op,
          ffi.Int version,
        )
      >
    >
    find_custom_op_v2,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolverV2(
      options,
      find_builtin_op_v2,
      find_custom_op_v2,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverV2Ptr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V2> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int32 op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V2> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolverV2');
  late final _TfLiteInterpreterOptionsSetOpResolverV2 =
      _TfLiteInterpreterOptionsSetOpResolverV2Ptr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V2> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int32 op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V2> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// \private
  /// Backward-compat version of TfLiteInterpreterOptionsSetOpResolver.
  ///
  /// WARNING: This function is deprecated / not an official part of the API, is
  /// only for binary backwards compatibility, and should not be called.
  void TfLiteInterpreterOptionsSetOpResolverV1(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V1> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Int32 op,
          ffi.Int version,
        )
      >
    >
    find_builtin_op_v1,
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<TfLiteRegistration_V1> Function(
          ffi.Pointer<ffi.Void> user_data,
          ffi.Pointer<ffi.Char> op,
          ffi.Int version,
        )
      >
    >
    find_custom_op_v1,
    ffi.Pointer<ffi.Void> op_resolver_user_data,
  ) {
    return _TfLiteInterpreterOptionsSetOpResolverV1(
      options,
      find_builtin_op_v1,
      find_custom_op_v1,
      op_resolver_user_data,
    );
  }

  late final _TfLiteInterpreterOptionsSetOpResolverV1Ptr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V1> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Int32 op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<
              ffi.NativeFunction<
                ffi.Pointer<TfLiteRegistration_V1> Function(
                  ffi.Pointer<ffi.Void> user_data,
                  ffi.Pointer<ffi.Char> op,
                  ffi.Int version,
                )
              >
            >,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('TfLiteInterpreterOptionsSetOpResolverV1');
  late final _TfLiteInterpreterOptionsSetOpResolverV1 =
      _TfLiteInterpreterOptionsSetOpResolverV1Ptr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V1> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Int32 op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<
            ffi.NativeFunction<
              ffi.Pointer<TfLiteRegistration_V1> Function(
                ffi.Pointer<ffi.Void> user_data,
                ffi.Pointer<ffi.Char> op,
                ffi.Int version,
              )
            >
          >,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Returns a new interpreter using the provided model and options, or null on
  /// failure, where the model uses only the operators explicitly added to the
  /// options.  This is the same as `TFLiteInterpreterCreate` from `c_api.h`,
  /// except that the only operators that are supported are the ones registered
  /// in `options` via calls to `TfLiteInterpreterOptionsSetOpResolver`,
  /// `TfLiteInterpreterOptionsAddBuiltinOp`, and/or
  /// `TfLiteInterpreterOptionsAddCustomOp`.
  ///
  /// * `model` must be a valid model instance. The caller retains ownership of
  /// the object, and can destroy it immediately after creating the interpreter;
  /// the interpreter will maintain its own reference to the underlying model
  /// data.
  /// * `options` should not be null. The caller retains ownership of the object,
  /// and can safely destroy it immediately after creating the interpreter.
  ///
  /// NOTE: The client *must* explicitly allocate tensors before attempting to
  /// access input tensor data or invoke the interpreter.
  ///
  /// WARNING: This is an experimental API and subject to change.
  ffi.Pointer<TfLiteInterpreter> TfLiteInterpreterCreateWithSelectedOps(
    ffi.Pointer<TfLiteModel> model,
    ffi.Pointer<TfLiteInterpreterOptions> options,
  ) {
    return _TfLiteInterpreterCreateWithSelectedOps(model, options);
  }

  late final _TfLiteInterpreterCreateWithSelectedOpsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteInterpreter> Function(
            ffi.Pointer<TfLiteModel>,
            ffi.Pointer<TfLiteInterpreterOptions>,
          )
        >
      >('TfLiteInterpreterCreateWithSelectedOps');
  late final _TfLiteInterpreterCreateWithSelectedOps =
      _TfLiteInterpreterCreateWithSelectedOpsPtr.asFunction<
        ffi.Pointer<TfLiteInterpreter> Function(
          ffi.Pointer<TfLiteModel>,
          ffi.Pointer<TfLiteInterpreterOptions>,
        )
      >();

  /// Enable or disable the NN API delegate for the interpreter (true to enable).
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsSetUseNNAPI(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    bool enable,
  ) {
    return _TfLiteInterpreterOptionsSetUseNNAPI(options, enable);
  }

  late final _TfLiteInterpreterOptionsSetUseNNAPIPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>, ffi.Bool)
        >
      >('TfLiteInterpreterOptionsSetUseNNAPI');
  late final _TfLiteInterpreterOptionsSetUseNNAPI =
      _TfLiteInterpreterOptionsSetUseNNAPIPtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreterOptions>, bool)
      >();

  /// Enable or disable CPU fallback for the interpreter (true to enable).
  /// If enabled, TfLiteInterpreterInvoke will do automatic fallback from
  /// executing with delegate(s) to regular execution without delegates
  /// (i.e. on CPU).
  ///
  /// Allowing the fallback is suitable only if both of the following hold:
  /// - The caller is known not to cache pointers to tensor data across
  /// TfLiteInterpreterInvoke calls.
  /// - The model is not stateful (no variables, no LSTMs) or the state isn't
  /// needed between batches.
  ///
  /// When delegate fallback is enabled, TfLiteInterpreterInvoke will
  /// behave as follows:
  /// If one or more delegates were set in the interpreter options
  /// (see TfLiteInterpreterOptionsAddDelegate),
  /// AND inference fails,
  /// then the interpreter will fall back to not using any delegates.
  /// In that case, the previously applied delegate(s) will be automatically
  /// undone, and an attempt will be made to return the interpreter to an
  /// invokable state, which may invalidate previous tensor addresses,
  /// and the inference will be attempted again, using input tensors with
  /// the same value as previously set.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsSetEnableDelegateFallback(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    bool enable,
  ) {
    return _TfLiteInterpreterOptionsSetEnableDelegateFallback(options, enable);
  }

  late final _TfLiteInterpreterOptionsSetEnableDelegateFallbackPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreterOptions>, ffi.Bool)
        >
      >('TfLiteInterpreterOptionsSetEnableDelegateFallback');
  late final _TfLiteInterpreterOptionsSetEnableDelegateFallback =
      _TfLiteInterpreterOptionsSetEnableDelegateFallbackPtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreterOptions>, bool)
      >();

  /// Allow a delegate to look at the graph and modify the graph to handle
  /// parts of the graph themselves. After this is called, the graph may
  /// contain new nodes that replace 1 more nodes.
  /// 'delegate' must outlive the interpreter.
  /// Use `TfLiteInterpreterOptionsAddDelegate` instead of this unless
  /// absolutely required.
  /// Returns one of the following three status codes:
  /// 1. kTfLiteOk: Success.
  /// 2. kTfLiteDelegateError: Delegation failed due to an error in the
  /// delegate. The Interpreter has been restored to its pre-delegation state.
  /// NOTE: This undoes all delegates previously applied to the Interpreter.
  /// 3. kTfLiteError: Unexpected/runtime failure.
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterModifyGraphWithDelegate(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    ffi.Pointer<TfLiteDelegate> delegate,
  ) {
    return _TfLiteInterpreterModifyGraphWithDelegate(interpreter, delegate);
  }

  late final _TfLiteInterpreterModifyGraphWithDelegatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Pointer<TfLiteDelegate>,
          )
        >
      >('TfLiteInterpreterModifyGraphWithDelegate');
  late final _TfLiteInterpreterModifyGraphWithDelegate =
      _TfLiteInterpreterModifyGraphWithDelegatePtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteInterpreter>,
          ffi.Pointer<TfLiteDelegate>,
        )
      >();

  /// Returns the tensor index corresponding to the input tensor
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterGetInputTensorIndex(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int input_index,
  ) {
    return _TfLiteInterpreterGetInputTensorIndex(interpreter, input_index);
  }

  late final _TfLiteInterpreterGetInputTensorIndexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>, ffi.Int32)
        >
      >('TfLiteInterpreterGetInputTensorIndex');
  late final _TfLiteInterpreterGetInputTensorIndex =
      _TfLiteInterpreterGetInputTensorIndexPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Returns the tensor index corresponding to the output tensor
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterGetOutputTensorIndex(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int output_index,
  ) {
    return _TfLiteInterpreterGetOutputTensorIndex(interpreter, output_index);
  }

  late final _TfLiteInterpreterGetOutputTensorIndexPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>, ffi.Int32)
        >
      >('TfLiteInterpreterGetOutputTensorIndex');
  late final _TfLiteInterpreterGetOutputTensorIndex =
      _TfLiteInterpreterGetOutputTensorIndexPtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Assigns (or reassigns) a custom memory allocation for the given
  /// tensor. `flags` is a bitmask, see TfLiteCustomAllocationFlags.
  /// The runtime does NOT take ownership of the underlying memory.
  ///
  /// NOTE: User needs to call TfLiteInterpreterAllocateTensors() after this.
  /// Invalid/insufficient buffers will cause an error during
  /// TfLiteInterpreterAllocateTensors or TfLiteInterpreterInvoke (in case of
  /// dynamic shapes in the graph).
  ///
  /// Parameters should satisfy the following conditions:
  /// 1. tensor->allocation_type == kTfLiteArenaRw or kTfLiteArenaRwPersistent
  /// In general, this is true for I/O tensors & variable tensors.
  /// 2. allocation->data has the appropriate permissions for runtime access
  /// (Read-only for inputs, Read-Write for others), and outlives
  /// TfLiteInterpreter.
  /// 3. allocation->bytes >= tensor->bytes.
  /// This condition is checked again if any tensors are resized.
  /// 4. allocation->data should be aligned to kDefaultTensorAlignment
  /// defined in lite/util.h. (Currently 64 bytes)
  /// This check is skipped if kTfLiteCustomAllocationFlagsSkipAlignCheck is
  /// set through `flags`.
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterSetCustomAllocationForTensor(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int tensor_index,
    ffi.Pointer<TfLiteCustomAllocation> allocation,
    int flags,
  ) {
    return _TfLiteInterpreterSetCustomAllocationForTensor(
      interpreter,
      tensor_index,
      allocation,
      flags,
    );
  }

  late final _TfLiteInterpreterSetCustomAllocationForTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int,
            ffi.Pointer<TfLiteCustomAllocation>,
            ffi.Int64,
          )
        >
      >('TfLiteInterpreterSetCustomAllocationForTensor');
  late final _TfLiteInterpreterSetCustomAllocationForTensor =
      _TfLiteInterpreterSetCustomAllocationForTensorPtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteInterpreter>,
          int,
          ffi.Pointer<TfLiteCustomAllocation>,
          int,
        )
      >();

  /// Sets the delegate buffer handle for the given tensor.
  ///
  /// This function sets the buffer handle for a tensor that is used by other
  /// computing hardware such as EdgeTpu. For example, EdgeTpu delegate imports a
  /// tensor's memory into EdgeTpu's virtual address and returns a buffer handle.
  /// Then EdgeTpu delegate calls this API to associate the tensor with the buffer
  /// handle.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterSetBufferHandle(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    ffi.Pointer<TfLiteTensor> tensor,
    int buffer_handle,
    ffi.Pointer<TfLiteOpaqueDelegate> delegate,
  ) {
    return _TfLiteInterpreterSetBufferHandle(
      interpreter,
      tensor,
      buffer_handle,
      delegate,
    );
  }

  late final _TfLiteInterpreterSetBufferHandlePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Pointer<TfLiteTensor>,
            TfLiteBufferHandle,
            ffi.Pointer<TfLiteOpaqueDelegate>,
          )
        >
      >('TfLiteInterpreterSetBufferHandle');
  late final _TfLiteInterpreterSetBufferHandle =
      _TfLiteInterpreterSetBufferHandlePtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteInterpreter>,
          ffi.Pointer<TfLiteTensor>,
          int,
          ffi.Pointer<TfLiteOpaqueDelegate>,
        )
      >();

  /// Gets the delegate buffer handle, and the delegate which can process
  /// the buffer handle.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterGetBufferHandle(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int tensor_index,
    ffi.Pointer<TfLiteBufferHandle> buffer_handle,
    ffi.Pointer<ffi.Pointer<TfLiteOpaqueDelegate>> delegate,
  ) {
    return _TfLiteInterpreterGetBufferHandle(
      interpreter,
      tensor_index,
      buffer_handle,
      delegate,
    );
  }

  late final _TfLiteInterpreterGetBufferHandlePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<TfLiteInterpreter>,
            ffi.Int,
            ffi.Pointer<TfLiteBufferHandle>,
            ffi.Pointer<ffi.Pointer<TfLiteOpaqueDelegate>>,
          )
        >
      >('TfLiteInterpreterGetBufferHandle');
  late final _TfLiteInterpreterGetBufferHandle =
      _TfLiteInterpreterGetBufferHandlePtr.asFunction<
        int Function(
          ffi.Pointer<TfLiteInterpreter>,
          int,
          ffi.Pointer<TfLiteBufferHandle>,
          ffi.Pointer<ffi.Pointer<TfLiteOpaqueDelegate>>,
        )
      >();

  /// Sets whether buffer handle output is allowed.
  /// When using hardware delegation, Interpreter will make the data of output
  /// tensors available in `tensor->data` by default. If the application can
  /// consume the buffer handle directly (e.g. reading output from OpenGL
  /// texture), it can set this flag to false, so Interpreter won't copy the
  /// data from buffer handle to CPU memory.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteSetAllowBufferHandleOutput(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    bool allow_buffer_handle_output,
  ) {
    return _TfLiteSetAllowBufferHandleOutput(
      interpreter,
      allow_buffer_handle_output,
    );
  }

  late final _TfLiteSetAllowBufferHandleOutputPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteInterpreter>, ffi.Bool)
        >
      >('TfLiteSetAllowBufferHandleOutput');
  late final _TfLiteSetAllowBufferHandleOutput =
      _TfLiteSetAllowBufferHandleOutputPtr.asFunction<
        void Function(ffi.Pointer<TfLiteInterpreter>, bool)
      >();

  /// Attempts to cancel in flight invocation if any.
  /// This will not affect calls to `Invoke` that happen after this.
  /// Non blocking and thread safe.
  /// Returns kTfLiteError if cancellation is not enabled, otherwise returns
  /// kTfLiteOk.
  /// NOTE: Calling this function will cancel in-flight invocations
  /// in all SignatureRunners built from the same interpreter.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteSignatureRunnerCancel(
    ffi.Pointer<TfLiteSignatureRunner> signature_runner,
  ) {
    return _TfLiteSignatureRunnerCancel(signature_runner);
  }

  late final _TfLiteSignatureRunnerCancelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteSignatureRunner>)
        >
      >('TfLiteSignatureRunnerCancel');
  late final _TfLiteSignatureRunnerCancel =
      _TfLiteSignatureRunnerCancelPtr.asFunction<
        int Function(ffi.Pointer<TfLiteSignatureRunner>)
      >();

  /// Registers the telemetry profiler to the interpreter.
  /// Note: The interpreter does not take the ownership of profiler, but callers
  /// must ensure profiler->data outlives the lifespan of the interpreter.
  ///
  /// WARNING: This is an experimental API and subject to change.
  void TfLiteInterpreterOptionsSetTelemetryProfiler(
    ffi.Pointer<TfLiteInterpreterOptions> options,
    ffi.Pointer<TfLiteTelemetryProfilerStruct> profiler,
  ) {
    return _TfLiteInterpreterOptionsSetTelemetryProfiler(options, profiler);
  }

  late final _TfLiteInterpreterOptionsSetTelemetryProfilerPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<TfLiteInterpreterOptions>,
            ffi.Pointer<TfLiteTelemetryProfilerStruct>,
          )
        >
      >('TfLiteInterpreterOptionsSetTelemetryProfiler');
  late final _TfLiteInterpreterOptionsSetTelemetryProfiler =
      _TfLiteInterpreterOptionsSetTelemetryProfilerPtr.asFunction<
        void Function(
          ffi.Pointer<TfLiteInterpreterOptions>,
          ffi.Pointer<TfLiteTelemetryProfilerStruct>,
        )
      >();

  /// Ensures the data of the tensor at the given index is readable.
  /// Note: If a delegate has been used, and `SetAllowBufferHandleOutput(true)`
  /// has been called, tensor outputs may be stored as delegate buffer handles
  /// whose data is not directly readable until this method has been called. In
  /// such cases, this method will copy the data from the delegate buffer handle
  /// to CPU memory.
  ///
  /// WARNING: This is an experimental API and subject to change.
  int TfLiteInterpreterEnsureTensorDataIsReadable(
    ffi.Pointer<TfLiteInterpreter> interpreter,
    int tensor_index,
  ) {
    return _TfLiteInterpreterEnsureTensorDataIsReadable(
      interpreter,
      tensor_index,
    );
  }

  late final _TfLiteInterpreterEnsureTensorDataIsReadablePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<TfLiteInterpreter>, ffi.Int)
        >
      >('TfLiteInterpreterEnsureTensorDataIsReadable');
  late final _TfLiteInterpreterEnsureTensorDataIsReadable =
      _TfLiteInterpreterEnsureTensorDataIsReadablePtr.asFunction<
        int Function(ffi.Pointer<TfLiteInterpreter>, int)
      >();

  /// Return a delegate that uses CoreML for ops execution.
  /// Must outlive the interpreter.
  ffi.Pointer<TfLiteDelegate> TfLiteCoreMlDelegateCreate(
    ffi.Pointer<TfLiteCoreMlDelegateOptions> options,
  ) {
    return _TfLiteCoreMlDelegateCreate(options);
  }

  late final _TfLiteCoreMlDelegateCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<TfLiteCoreMlDelegateOptions>,
          )
        >
      >('TfLiteCoreMlDelegateCreate');
  late final _TfLiteCoreMlDelegateCreate =
      _TfLiteCoreMlDelegateCreatePtr.asFunction<
        ffi.Pointer<TfLiteDelegate> Function(
          ffi.Pointer<TfLiteCoreMlDelegateOptions>,
        )
      >();

  /// Do any needed cleanup and delete 'delegate'.
  void TfLiteCoreMlDelegateDelete(ffi.Pointer<TfLiteDelegate> delegate) {
    return _TfLiteCoreMlDelegateDelete(delegate);
  }

  late final _TfLiteCoreMlDelegateDeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteDelegate>)>
      >('TfLiteCoreMlDelegateDelete');
  late final _TfLiteCoreMlDelegateDelete =
      _TfLiteCoreMlDelegateDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteDelegate>)
      >();

  /// Populates TFLGpuDelegateOptions as follows:
  /// allow_precision_loss = false;
  /// wait_type = TFLGpuDelegateWaitType::TFLGpuDelegateWaitTypePassive;
  /// enable_quantization = true;
  TFLGpuDelegateOptions TFLGpuDelegateOptionsDefault() {
    return _TFLGpuDelegateOptionsDefault();
  }

  late final _TFLGpuDelegateOptionsDefaultPtr =
      _lookup<ffi.NativeFunction<TFLGpuDelegateOptions Function()>>(
        'TFLGpuDelegateOptionsDefault',
      );
  late final _TFLGpuDelegateOptionsDefault =
      _TFLGpuDelegateOptionsDefaultPtr.asFunction<
        TFLGpuDelegateOptions Function()
      >();

  /// Creates a new delegate instance that need to be destroyed with
  /// `TFLDeleteTfLiteGpuDelegate` when delegate is no longer used by TFLite.
  /// When `options` is set to `nullptr`, the following default values are used:
  /// .precision_loss_allowed = false,
  /// .wait_type = kPassive,
  ffi.Pointer<TfLiteDelegate> TFLGpuDelegateCreate(
    ffi.Pointer<TFLGpuDelegateOptions> options,
  ) {
    return _TFLGpuDelegateCreate(options);
  }

  late final _TFLGpuDelegateCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<TFLGpuDelegateOptions>,
          )
        >
      >('TFLGpuDelegateCreate');
  late final _TFLGpuDelegateCreate =
      _TFLGpuDelegateCreatePtr.asFunction<
        ffi.Pointer<TfLiteDelegate> Function(ffi.Pointer<TFLGpuDelegateOptions>)
      >();

  /// Destroys a delegate created with `TFLGpuDelegateCreate` call.
  void TFLGpuDelegateDelete(ffi.Pointer<TfLiteDelegate> delegate) {
    return _TFLGpuDelegateDelete(delegate);
  }

  late final _TFLGpuDelegateDeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteDelegate>)>
      >('TFLGpuDelegateDelete');
  late final _TFLGpuDelegateDelete =
      _TFLGpuDelegateDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteDelegate>)
      >();

  /// Binds Metal buffer to an input or an output tensor in the initialized
  /// delegate. Bound buffer should have sufficient storage to accommodate all
  /// elements of a tensor. For quantized model, the buffer is bound to internal
  /// dequantized float32 tensor.
  /// Returns non-zero on success, or zero otherwise.
  ///
  /// *** Must be called *after* `Interpreter::ModifyGraphWithDelegate`. ***
  /// WARNING: This is an experimental API and subject to change.
  bool TFLGpuDelegateBindMetalBufferToTensor(
    ffi.Pointer<TfLiteDelegate> delegate,
    int tensor_index,
    int metal_buffer,
  ) {
    return _TFLGpuDelegateBindMetalBufferToTensor(
      delegate,
      tensor_index,
      metal_buffer,
    );
  }

  late final _TFLGpuDelegateBindMetalBufferToTensorPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<TfLiteDelegate>, ffi.Int, ffi.Int)
        >
      >('TFLGpuDelegateBindMetalBufferToTensor');
  late final _TFLGpuDelegateBindMetalBufferToTensor =
      _TFLGpuDelegateBindMetalBufferToTensorPtr.asFunction<
        bool Function(ffi.Pointer<TfLiteDelegate>, int, int)
      >();

  /// Returns true on systems that support running the in-memory weight cache
  /// provider.
  bool TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProvider() {
    return _TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProvider();
  }

  late final _TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProviderPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>(
        'TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProvider',
      );
  late final _TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProvider =
      _TfLiteXNNPackDelegateCanUseInMemoryWeightCacheProviderPtr.asFunction<
        bool Function()
      >();

  /// Returns a file path that will activate the in-memory weight cache that
  /// enables weight deduplication.
  ffi.Pointer<ffi.Char> TfLiteXNNPackDelegateInMemoryFilePath() {
    return _TfLiteXNNPackDelegateInMemoryFilePath();
  }

  late final _TfLiteXNNPackDelegateInMemoryFilePathPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'TfLiteXNNPackDelegateInMemoryFilePath',
      );
  late final _TfLiteXNNPackDelegateInMemoryFilePath =
      _TfLiteXNNPackDelegateInMemoryFilePathPtr.asFunction<
        ffi.Pointer<ffi.Char> Function()
      >();

  /// Returns a structure with the default XNNPack delegate options.
  TfLiteXNNPackDelegateOptions TfLiteXNNPackDelegateOptionsDefault() {
    return _TfLiteXNNPackDelegateOptionsDefault();
  }

  late final _TfLiteXNNPackDelegateOptionsDefaultPtr =
      _lookup<ffi.NativeFunction<TfLiteXNNPackDelegateOptions Function()>>(
        'TfLiteXNNPackDelegateOptionsDefault',
      );
  late final _TfLiteXNNPackDelegateOptionsDefault =
      _TfLiteXNNPackDelegateOptionsDefaultPtr.asFunction<
        TfLiteXNNPackDelegateOptions Function()
      >();

  /// Creates a new delegate instance that need to be destroyed with
  /// `TfLiteXNNPackDelegateDelete` when delegate is no longer used by TFLite.
  /// When `options` is set to `nullptr`, default values are used (see
  /// implementation of TfLiteXNNPackDelegateOptionsDefault in the .cc file for
  /// details).
  ffi.Pointer<TfLiteDelegate> TfLiteXNNPackDelegateCreate(
    ffi.Pointer<TfLiteXNNPackDelegateOptions> options,
  ) {
    return _TfLiteXNNPackDelegateCreate(options);
  }

  late final _TfLiteXNNPackDelegateCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<TfLiteXNNPackDelegateOptions>,
          )
        >
      >('TfLiteXNNPackDelegateCreate');
  late final _TfLiteXNNPackDelegateCreate =
      _TfLiteXNNPackDelegateCreatePtr.asFunction<
        ffi.Pointer<TfLiteDelegate> Function(
          ffi.Pointer<TfLiteXNNPackDelegateOptions>,
        )
      >();

  /// Performs the same task as TfLiteXNNPackDelegateCreate, with one exception.
  /// If the context passed contains a non-null xnnpack_threadpool field,
  /// we will use it as the threadpool for the delegate created.
  ffi.Pointer<TfLiteDelegate> TfLiteXNNPackDelegateCreateWithThreadpool(
    ffi.Pointer<TfLiteXNNPackDelegateOptions> options,
    ffi.Pointer<TfLiteContext> context,
  ) {
    return _TfLiteXNNPackDelegateCreateWithThreadpool(options, context);
  }

  late final _TfLiteXNNPackDelegateCreateWithThreadpoolPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<TfLiteXNNPackDelegateOptions>,
            ffi.Pointer<TfLiteContext>,
          )
        >
      >('TfLiteXNNPackDelegateCreateWithThreadpool');
  late final _TfLiteXNNPackDelegateCreateWithThreadpool =
      _TfLiteXNNPackDelegateCreateWithThreadpoolPtr.asFunction<
        ffi.Pointer<TfLiteDelegate> Function(
          ffi.Pointer<TfLiteXNNPackDelegateOptions>,
          ffi.Pointer<TfLiteContext>,
        )
      >();

  /// Returns the pthreadpool_t object used for parallelization in XNNPACK.
  /// Can return NULL if the XNNPack delegate is single-threaded.
  ///
  /// WARNING: This API is experimental and subject to change.
  ffi.Pointer<ffi.Void> TfLiteXNNPackDelegateGetThreadPool(
    ffi.Pointer<TfLiteDelegate> delegate,
  ) {
    return _TfLiteXNNPackDelegateGetThreadPool(delegate);
  }

  late final _TfLiteXNNPackDelegateGetThreadPoolPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteDelegate>)
        >
      >('TfLiteXNNPackDelegateGetThreadPool');
  late final _TfLiteXNNPackDelegateGetThreadPool =
      _TfLiteXNNPackDelegateGetThreadPoolPtr.asFunction<
        ffi.Pointer<ffi.Void> Function(ffi.Pointer<TfLiteDelegate>)
      >();

  /// Returns the options in the delegate.
  /// Returns NULL if the delegate is NULL.
  ///
  /// WARNING: This API is experimental and subject to change.
  ffi.Pointer<TfLiteXNNPackDelegateOptions> TfLiteXNNPackDelegateGetOptions(
    ffi.Pointer<TfLiteDelegate> delegate,
  ) {
    return _TfLiteXNNPackDelegateGetOptions(delegate);
  }

  late final _TfLiteXNNPackDelegateGetOptionsPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteXNNPackDelegateOptions> Function(
            ffi.Pointer<TfLiteDelegate>,
          )
        >
      >('TfLiteXNNPackDelegateGetOptions');
  late final _TfLiteXNNPackDelegateGetOptions =
      _TfLiteXNNPackDelegateGetOptionsPtr.asFunction<
        ffi.Pointer<TfLiteXNNPackDelegateOptions> Function(
          ffi.Pointer<TfLiteDelegate>,
        )
      >();

  /// Returns the flags used for an XNNPack delegate.
  /// See documentation for TfLiteXNNPackDelegateOptions.flags.
  ///
  /// WARNING: This API is experimental and subject to change.
  int TfLiteXNNPackDelegateGetFlags(ffi.Pointer<TfLiteDelegate> delegate) {
    return _TfLiteXNNPackDelegateGetFlags(delegate);
  }

  late final _TfLiteXNNPackDelegateGetFlagsPtr =
      _lookup<
        ffi.NativeFunction<ffi.Int Function(ffi.Pointer<TfLiteDelegate>)>
      >('TfLiteXNNPackDelegateGetFlags');
  late final _TfLiteXNNPackDelegateGetFlags =
      _TfLiteXNNPackDelegateGetFlagsPtr.asFunction<
        int Function(ffi.Pointer<TfLiteDelegate>)
      >();

  /// Destroys a delegate created with `TfLiteXNNPackDelegateCreate` call.
  void TfLiteXNNPackDelegateDelete(ffi.Pointer<TfLiteDelegate> delegate) {
    return _TfLiteXNNPackDelegateDelete(delegate);
  }

  late final _TfLiteXNNPackDelegateDeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteDelegate>)>
      >('TfLiteXNNPackDelegateDelete');
  late final _TfLiteXNNPackDelegateDelete =
      _TfLiteXNNPackDelegateDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteDelegate>)
      >();

  /// Creates a new weights cache that can be shared with multiple delegate
  /// instances. Prefer TfLiteXNNPackDelegateWeightsCacheCreateWithSize which can
  /// reduce memory bandwidth.
  ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>
  TfLiteXNNPackDelegateWeightsCacheCreate() {
    return _TfLiteXNNPackDelegateWeightsCacheCreate();
  }

  late final _TfLiteXNNPackDelegateWeightsCacheCreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> Function()
        >
      >('TfLiteXNNPackDelegateWeightsCacheCreate');
  late final _TfLiteXNNPackDelegateWeightsCacheCreate =
      _TfLiteXNNPackDelegateWeightsCacheCreatePtr.asFunction<
        ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> Function()
      >();

  /// Creates a new weights cache with a specified initial size that can be shared
  /// with multiple delegate instances. The weights cache can hold up to size bytes
  /// without growing.
  ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>
  TfLiteXNNPackDelegateWeightsCacheCreateWithSize(int size) {
    return _TfLiteXNNPackDelegateWeightsCacheCreateWithSize(size);
  }

  late final _TfLiteXNNPackDelegateWeightsCacheCreateWithSizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> Function(ffi.Size)
        >
      >('TfLiteXNNPackDelegateWeightsCacheCreateWithSize');
  late final _TfLiteXNNPackDelegateWeightsCacheCreateWithSize =
      _TfLiteXNNPackDelegateWeightsCacheCreateWithSizePtr.asFunction<
        ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> Function(int)
      >();

  /// Soft-finalize a weights cache. Extra space will be left in the weights cache
  /// to allow for cache "insertion" only if it is a cache hit. This has memory
  /// overhead compared to TfLiteXNNPackDelegateWeightsCacheFinalizeHard. Use this
  /// if the number of interpreter instances using XNNPACK delegate is not fixed
  /// (e.g. created based on workload in a server daemon).
  /// Returns true on success, false on error.
  bool TfLiteXNNPackDelegateWeightsCacheFinalizeSoft(
    ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> cache,
  ) {
    return _TfLiteXNNPackDelegateWeightsCacheFinalizeSoft(cache);
  }

  late final _TfLiteXNNPackDelegateWeightsCacheFinalizeSoftPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
        >
      >('TfLiteXNNPackDelegateWeightsCacheFinalizeSoft');
  late final _TfLiteXNNPackDelegateWeightsCacheFinalizeSoft =
      _TfLiteXNNPackDelegateWeightsCacheFinalizeSoftPtr.asFunction<
        bool Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
      >();

  /// Hard-finalize a weights cache, cache is effectively frozen and no more cache
  /// operations are allowed. Memory is resized to smallest possible. Use this if
  /// the number of interpreter instances using XNNPACK delegate can be fixed and
  /// all creation of instances can happen up front. This has the lowest memory
  /// usage.
  /// Returns true on success, false on error.
  bool TfLiteXNNPackDelegateWeightsCacheFinalizeHard(
    ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> cache,
  ) {
    return _TfLiteXNNPackDelegateWeightsCacheFinalizeHard(cache);
  }

  late final _TfLiteXNNPackDelegateWeightsCacheFinalizeHardPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
        >
      >('TfLiteXNNPackDelegateWeightsCacheFinalizeHard');
  late final _TfLiteXNNPackDelegateWeightsCacheFinalizeHard =
      _TfLiteXNNPackDelegateWeightsCacheFinalizeHardPtr.asFunction<
        bool Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
      >();

  /// Destroys a weights cache created with
  /// `TfLiteXNNPackDelegateWeightsCacheCreate` call.
  void TfLiteXNNPackDelegateWeightsCacheDelete(
    ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> cache,
  ) {
    return _TfLiteXNNPackDelegateWeightsCacheDelete(cache);
  }

  late final _TfLiteXNNPackDelegateWeightsCacheDeletePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
        >
      >('TfLiteXNNPackDelegateWeightsCacheDelete');
  late final _TfLiteXNNPackDelegateWeightsCacheDelete =
      _TfLiteXNNPackDelegateWeightsCacheDeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteXNNPackDelegateWeightsCache>)
      >();

  /// Populates TfLiteGpuDelegateOptionsV2 as follows:
  /// is_precision_loss_allowed = false
  /// inference_preference = TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER
  /// priority1 = TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION
  /// priority2 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO
  /// priority3 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO
  /// experimental_flags = TFLITE_GPU_EXPERIMENTAL_FLAGS_ENABLE_QUANT
  /// max_delegated_partitions = 1
  TfLiteGpuDelegateOptionsV2 TfLiteGpuDelegateOptionsV2Default() {
    return _TfLiteGpuDelegateOptionsV2Default();
  }

  late final _TfLiteGpuDelegateOptionsV2DefaultPtr =
      _lookup<ffi.NativeFunction<TfLiteGpuDelegateOptionsV2 Function()>>(
        'TfLiteGpuDelegateOptionsV2Default',
      );
  late final _TfLiteGpuDelegateOptionsV2Default =
      _TfLiteGpuDelegateOptionsV2DefaultPtr.asFunction<
        TfLiteGpuDelegateOptionsV2 Function()
      >();

  /// Creates a new delegate instance that need to be destroyed with
  /// TfLiteGpuDelegateV2Delete when delegate is no longer used by TFLite.
  ///
  /// This delegate encapsulates multiple GPU-acceleration APIs under the hood to
  /// make use of the fastest available on a device.
  ///
  /// When `options` is set to `nullptr`, then default options are used.
  ///
  /// `TfLiteGpuDelegateV2Create` creates an instance for use with the synchronous
  /// API.  `TfLiteGpuDelegateV2CreateAsync` creates an instance for use with the
  /// asynchronous API.
  ffi.Pointer<TfLiteDelegate> TfLiteGpuDelegateV2Create(
    ffi.Pointer<TfLiteGpuDelegateOptionsV2> options,
  ) {
    return _TfLiteGpuDelegateV2Create(options);
  }

  late final _TfLiteGpuDelegateV2CreatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<TfLiteGpuDelegateOptionsV2>,
          )
        >
      >('TfLiteGpuDelegateV2Create');
  late final _TfLiteGpuDelegateV2Create =
      _TfLiteGpuDelegateV2CreatePtr.asFunction<
        ffi.Pointer<TfLiteDelegate> Function(
          ffi.Pointer<TfLiteGpuDelegateOptionsV2>,
        )
      >();

  /// Destroys a delegate created with `TfLiteGpuDelegateV2Create` call.
  void TfLiteGpuDelegateV2Delete(ffi.Pointer<TfLiteDelegate> delegate) {
    return _TfLiteGpuDelegateV2Delete(delegate);
  }

  late final _TfLiteGpuDelegateV2DeletePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteDelegate>)>
      >('TfLiteGpuDelegateV2Delete');
  late final _TfLiteGpuDelegateV2Delete =
      _TfLiteGpuDelegateV2DeletePtr.asFunction<
        void Function(ffi.Pointer<TfLiteDelegate>)
      >();

  ffi.Pointer<TfLiteDelegate> tflite_plugin_create_delegate(
    ffi.Pointer<ffi.Pointer<ffi.Char>> options_keys,
    ffi.Pointer<ffi.Pointer<ffi.Char>> options_values,
    int num_options,
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>
    report_error,
  ) {
    return _tflite_plugin_create_delegate(
      options_keys,
      options_values,
      num_options,
      report_error,
    );
  }

  late final _tflite_plugin_create_delegatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<TfLiteDelegate> Function(
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Pointer<ffi.Pointer<ffi.Char>>,
            ffi.Size,
            ffi.Pointer<
              ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>
            >,
          )
        >
      >('tflite_plugin_create_delegate');
  late final _tflite_plugin_create_delegate = _tflite_plugin_create_delegatePtr
      .asFunction<
        ffi.Pointer<TfLiteDelegate> Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>,
          int,
          ffi.Pointer<
            ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>
          >,
        )
      >();

  void tflite_plugin_destroy_delegate(ffi.Pointer<TfLiteDelegate> delegate) {
    return _tflite_plugin_destroy_delegate(delegate);
  }

  late final _tflite_plugin_destroy_delegatePtr =
      _lookup<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<TfLiteDelegate>)>
      >('tflite_plugin_destroy_delegate');
  late final _tflite_plugin_destroy_delegate =
      _tflite_plugin_destroy_delegatePtr
          .asFunction<void Function(ffi.Pointer<TfLiteDelegate>)>();
}

final class TfLiteOperator extends ffi.Opaque {}

/// The enum for builtin operators.
/// Note: CUSTOM, DELEGATE, and PLACEHOLDER_FOR_GREATER_OP_CODES are 3 special
/// ops which are not real built-in ops.
abstract class TfLiteBuiltinOperator {
  static const int kTfLiteBuiltinAdd = 0;
  static const int kTfLiteBuiltinAveragePool2d = 1;
  static const int kTfLiteBuiltinConcatenation = 2;
  static const int kTfLiteBuiltinConv2d = 3;
  static const int kTfLiteBuiltinDepthwiseConv2d = 4;
  static const int kTfLiteBuiltinDepthToSpace = 5;
  static const int kTfLiteBuiltinDequantize = 6;
  static const int kTfLiteBuiltinEmbeddingLookup = 7;
  static const int kTfLiteBuiltinFloor = 8;
  static const int kTfLiteBuiltinFullyConnected = 9;
  static const int kTfLiteBuiltinHashtableLookup = 10;
  static const int kTfLiteBuiltinL2Normalization = 11;
  static const int kTfLiteBuiltinL2Pool2d = 12;
  static const int kTfLiteBuiltinLocalResponseNormalization = 13;
  static const int kTfLiteBuiltinLogistic = 14;
  static const int kTfLiteBuiltinLshProjection = 15;
  static const int kTfLiteBuiltinLstm = 16;
  static const int kTfLiteBuiltinMaxPool2d = 17;
  static const int kTfLiteBuiltinMul = 18;
  static const int kTfLiteBuiltinRelu = 19;
  static const int kTfLiteBuiltinReluN1To1 = 20;
  static const int kTfLiteBuiltinRelu6 = 21;
  static const int kTfLiteBuiltinReshape = 22;
  static const int kTfLiteBuiltinResizeBilinear = 23;
  static const int kTfLiteBuiltinRnn = 24;
  static const int kTfLiteBuiltinSoftmax = 25;
  static const int kTfLiteBuiltinSpaceToDepth = 26;
  static const int kTfLiteBuiltinSvdf = 27;
  static const int kTfLiteBuiltinTanh = 28;
  static const int kTfLiteBuiltinConcatEmbeddings = 29;
  static const int kTfLiteBuiltinSkipGram = 30;
  static const int kTfLiteBuiltinCall = 31;
  static const int kTfLiteBuiltinCustom = 32;
  static const int kTfLiteBuiltinEmbeddingLookupSparse = 33;
  static const int kTfLiteBuiltinPad = 34;
  static const int kTfLiteBuiltinUnidirectionalSequenceRnn = 35;
  static const int kTfLiteBuiltinGather = 36;
  static const int kTfLiteBuiltinBatchToSpaceNd = 37;
  static const int kTfLiteBuiltinSpaceToBatchNd = 38;
  static const int kTfLiteBuiltinTranspose = 39;
  static const int kTfLiteBuiltinMean = 40;
  static const int kTfLiteBuiltinSub = 41;
  static const int kTfLiteBuiltinDiv = 42;
  static const int kTfLiteBuiltinSqueeze = 43;
  static const int kTfLiteBuiltinUnidirectionalSequenceLstm = 44;
  static const int kTfLiteBuiltinStridedSlice = 45;
  static const int kTfLiteBuiltinBidirectionalSequenceRnn = 46;
  static const int kTfLiteBuiltinExp = 47;
  static const int kTfLiteBuiltinTopkV2 = 48;
  static const int kTfLiteBuiltinSplit = 49;
  static const int kTfLiteBuiltinLogSoftmax = 50;
  static const int kTfLiteBuiltinDelegate = 51;
  static const int kTfLiteBuiltinBidirectionalSequenceLstm = 52;
  static const int kTfLiteBuiltinCast = 53;
  static const int kTfLiteBuiltinPrelu = 54;
  static const int kTfLiteBuiltinMaximum = 55;
  static const int kTfLiteBuiltinArgMax = 56;
  static const int kTfLiteBuiltinMinimum = 57;
  static const int kTfLiteBuiltinLess = 58;
  static const int kTfLiteBuiltinNeg = 59;
  static const int kTfLiteBuiltinPadv2 = 60;
  static const int kTfLiteBuiltinGreater = 61;
  static const int kTfLiteBuiltinGreaterEqual = 62;
  static const int kTfLiteBuiltinLessEqual = 63;
  static const int kTfLiteBuiltinSelect = 64;
  static const int kTfLiteBuiltinSlice = 65;
  static const int kTfLiteBuiltinSin = 66;
  static const int kTfLiteBuiltinTransposeConv = 67;
  static const int kTfLiteBuiltinSparseToDense = 68;
  static const int kTfLiteBuiltinTile = 69;
  static const int kTfLiteBuiltinExpandDims = 70;
  static const int kTfLiteBuiltinEqual = 71;
  static const int kTfLiteBuiltinNotEqual = 72;
  static const int kTfLiteBuiltinLog = 73;
  static const int kTfLiteBuiltinSum = 74;
  static const int kTfLiteBuiltinSqrt = 75;
  static const int kTfLiteBuiltinRsqrt = 76;
  static const int kTfLiteBuiltinShape = 77;
  static const int kTfLiteBuiltinPow = 78;
  static const int kTfLiteBuiltinArgMin = 79;
  static const int kTfLiteBuiltinFakeQuant = 80;
  static const int kTfLiteBuiltinReduceProd = 81;
  static const int kTfLiteBuiltinReduceMax = 82;
  static const int kTfLiteBuiltinPack = 83;
  static const int kTfLiteBuiltinLogicalOr = 84;
  static const int kTfLiteBuiltinOneHot = 85;
  static const int kTfLiteBuiltinLogicalAnd = 86;
  static const int kTfLiteBuiltinLogicalNot = 87;
  static const int kTfLiteBuiltinUnpack = 88;
  static const int kTfLiteBuiltinReduceMin = 89;
  static const int kTfLiteBuiltinFloorDiv = 90;
  static const int kTfLiteBuiltinReduceAny = 91;
  static const int kTfLiteBuiltinSquare = 92;
  static const int kTfLiteBuiltinZerosLike = 93;
  static const int kTfLiteBuiltinFill = 94;
  static const int kTfLiteBuiltinFloorMod = 95;
  static const int kTfLiteBuiltinRange = 96;
  static const int kTfLiteBuiltinResizeNearestNeighbor = 97;
  static const int kTfLiteBuiltinLeakyRelu = 98;
  static const int kTfLiteBuiltinSquaredDifference = 99;
  static const int kTfLiteBuiltinMirrorPad = 100;
  static const int kTfLiteBuiltinAbs = 101;
  static const int kTfLiteBuiltinSplitV = 102;
  static const int kTfLiteBuiltinUnique = 103;
  static const int kTfLiteBuiltinCeil = 104;
  static const int kTfLiteBuiltinReverseV2 = 105;
  static const int kTfLiteBuiltinAddN = 106;
  static const int kTfLiteBuiltinGatherNd = 107;
  static const int kTfLiteBuiltinCos = 108;
  static const int kTfLiteBuiltinWhere = 109;
  static const int kTfLiteBuiltinRank = 110;
  static const int kTfLiteBuiltinElu = 111;
  static const int kTfLiteBuiltinReverseSequence = 112;
  static const int kTfLiteBuiltinMatrixDiag = 113;
  static const int kTfLiteBuiltinQuantize = 114;
  static const int kTfLiteBuiltinMatrixSetDiag = 115;
  static const int kTfLiteBuiltinRound = 116;
  static const int kTfLiteBuiltinHardSwish = 117;
  static const int kTfLiteBuiltinIf = 118;
  static const int kTfLiteBuiltinWhile = 119;
  static const int kTfLiteBuiltinNonMaxSuppressionV4 = 120;
  static const int kTfLiteBuiltinNonMaxSuppressionV5 = 121;
  static const int kTfLiteBuiltinScatterNd = 122;
  static const int kTfLiteBuiltinSelectV2 = 123;
  static const int kTfLiteBuiltinDensify = 124;
  static const int kTfLiteBuiltinSegmentSum = 125;
  static const int kTfLiteBuiltinBatchMatmul = 126;
  static const int kTfLiteBuiltinPlaceholderForGreaterOpCodes = 127;
  static const int kTfLiteBuiltinCumsum = 128;
  static const int kTfLiteBuiltinCallOnce = 129;
  static const int kTfLiteBuiltinBroadcastTo = 130;
  static const int kTfLiteBuiltinRfft2d = 131;
  static const int kTfLiteBuiltinConv3d = 132;
  static const int kTfLiteBuiltinImag = 133;
  static const int kTfLiteBuiltinReal = 134;
  static const int kTfLiteBuiltinComplexAbs = 135;
  static const int kTfLiteBuiltinHashtable = 136;
  static const int kTfLiteBuiltinHashtableFind = 137;
  static const int kTfLiteBuiltinHashtableImport = 138;
  static const int kTfLiteBuiltinHashtableSize = 139;
  static const int kTfLiteBuiltinReduceAll = 140;
  static const int kTfLiteBuiltinConv3dTranspose = 141;
  static const int kTfLiteBuiltinVarHandle = 142;
  static const int kTfLiteBuiltinReadVariable = 143;
  static const int kTfLiteBuiltinAssignVariable = 144;
  static const int kTfLiteBuiltinBroadcastArgs = 145;
  static const int kTfLiteBuiltinRandomStandardNormal = 146;
  static const int kTfLiteBuiltinBucketize = 147;
  static const int kTfLiteBuiltinRandomUniform = 148;
  static const int kTfLiteBuiltinMultinomial = 149;
  static const int kTfLiteBuiltinGelu = 150;
  static const int kTfLiteBuiltinDynamicUpdateSlice = 151;
  static const int kTfLiteBuiltinRelu0To1 = 152;
  static const int kTfLiteBuiltinUnsortedSegmentProd = 153;
  static const int kTfLiteBuiltinUnsortedSegmentMax = 154;
  static const int kTfLiteBuiltinUnsortedSegmentSum = 155;
  static const int kTfLiteBuiltinAtan2 = 156;
  static const int kTfLiteBuiltinUnsortedSegmentMin = 157;
  static const int kTfLiteBuiltinSign = 158;
  static const int kTfLiteBuiltinBitcast = 159;
  static const int kTfLiteBuiltinBitwiseXor = 160;
  static const int kTfLiteBuiltinRightShift = 161;
  static const int kTfLiteBuiltinStablehloLogistic = 162;
  static const int kTfLiteBuiltinStablehloAdd = 163;
  static const int kTfLiteBuiltinStablehloDivide = 164;
  static const int kTfLiteBuiltinStablehloMultiply = 165;
  static const int kTfLiteBuiltinStablehloMaximum = 166;
  static const int kTfLiteBuiltinStablehloReshape = 167;
  static const int kTfLiteBuiltinStablehloClamp = 168;
  static const int kTfLiteBuiltinStablehloConcatenate = 169;
  static const int kTfLiteBuiltinStablehloBroadcastInDim = 170;
  static const int kTfLiteBuiltinStablehloConvolution = 171;
  static const int kTfLiteBuiltinStablehloSlice = 172;
  static const int kTfLiteBuiltinStablehloCustomCall = 173;
  static const int kTfLiteBuiltinStablehloReduce = 174;
  static const int kTfLiteBuiltinStablehloAbs = 175;
  static const int kTfLiteBuiltinStablehloAnd = 176;
  static const int kTfLiteBuiltinStablehloCosine = 177;
  static const int kTfLiteBuiltinStablehloExponential = 178;
  static const int kTfLiteBuiltinStablehloFloor = 179;
  static const int kTfLiteBuiltinStablehloLog = 180;
  static const int kTfLiteBuiltinStablehloMinimum = 181;
  static const int kTfLiteBuiltinStablehloNegate = 182;
  static const int kTfLiteBuiltinStablehloOr = 183;
  static const int kTfLiteBuiltinStablehloPower = 184;
  static const int kTfLiteBuiltinStablehloRemainder = 185;
  static const int kTfLiteBuiltinStablehloRsqrt = 186;
  static const int kTfLiteBuiltinStablehloSelect = 187;
  static const int kTfLiteBuiltinStablehloSubtract = 188;
  static const int kTfLiteBuiltinStablehloTanh = 189;
  static const int kTfLiteBuiltinStablehloScatter = 190;
  static const int kTfLiteBuiltinStablehloCompare = 191;
  static const int kTfLiteBuiltinStablehloConvert = 192;
  static const int kTfLiteBuiltinStablehloDynamicSlice = 193;
  static const int kTfLiteBuiltinStablehloDynamicUpdateSlice = 194;
  static const int kTfLiteBuiltinStablehloPad = 195;
  static const int kTfLiteBuiltinStablehloIota = 196;
  static const int kTfLiteBuiltinStablehloDotGeneral = 197;
  static const int kTfLiteBuiltinStablehloReduceWindow = 198;
  static const int kTfLiteBuiltinStablehloSort = 199;
  static const int kTfLiteBuiltinStablehloWhile = 200;
  static const int kTfLiteBuiltinStablehloGather = 201;
  static const int kTfLiteBuiltinStablehloTranspose = 202;
  static const int kTfLiteBuiltinDilate = 203;
  static const int kTfLiteBuiltinStablehloRngBitGenerator = 204;
  static const int kTfLiteBuiltinReduceWindow = 205;
  static const int kTfLiteBuiltinStablehloComposite = 206;
  static const int kTfLiteBuiltinStablehloShiftLeft = 207;
  static const int kTfLiteBuiltinStablehloCbrt = 208;
  static const int kTfLiteBuiltinStablehloCase = 209;
}

final class TfLiteOpaqueContext extends ffi.Opaque {}

/// Note that new error status values may be added in future in order to
/// indicate more fine-grained internal states, therefore, applications should
/// not rely on status values being members of the enum.
abstract class TfLiteStatus {
  /// Success
  static const int kTfLiteOk = 0;

  /// Generally referring to an error in the runtime (i.e. interpreter)
  static const int kTfLiteError = 1;

  /// Generally referring to an error from a TfLiteDelegate itself.
  static const int kTfLiteDelegateError = 2;

  /// Generally referring to an error in applying a delegate due to
  /// incompatibility between runtime and delegate, e.g., this error is returned
  /// when trying to apply a TF Lite delegate onto a model graph that's already
  /// immutable.
  static const int kTfLiteApplicationError = 3;

  /// Generally referring to serialized delegate data not being found.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataNotFound = 4;

  /// Generally referring to data-writing issues in delegate serialization.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataWriteError = 5;

  /// Generally referring to data-reading issues in delegate serialization.
  /// See tflite::delegates::Serialization.
  static const int kTfLiteDelegateDataReadError = 6;

  /// Generally referring to issues when the TF Lite model has ops that cannot
  /// be resolved at runtime. This could happen when the specific op is not
  /// registered or built with the TF Lite framework.
  static const int kTfLiteUnresolvedOps = 7;

  /// Generally referring to invocation cancelled by the user.
  /// See `interpreter::Cancel`.
  /// TODO(b/194915839): Implement `interpreter::Cancel`.
  /// TODO(b/250636993): Cancellation triggered by `SetCancellationFunction`
  /// should also return this status code.
  static const int kTfLiteCancelled = 8;

  /// This status is returned by Prepare when the output shape cannot be
  /// determined but the size of the output tensor is known. For example, the
  /// output of reshape is always the same size as the input. This means that
  /// such ops may be
  /// done in place.
  static const int kTfLiteOutputShapeNotKnown = 9;
}

final class TfLiteOpaqueNode extends ffi.Opaque {}

final class TfLiteAsyncKernel extends ffi.Opaque {}

final class TfLiteModel extends ffi.Opaque {}

final class TfLiteInterpreterOptions extends ffi.Opaque {}

final class TfLiteInterpreter extends ffi.Opaque {}

final class TfLiteTensor extends ffi.Struct {
  /// The data type specification for data stored in `data`. This affects
  /// what member of `data` union should be used.
  @ffi.Int32()
  external int type;

  /// A union of data pointers. The appropriate type should be used for a typed
  /// tensor based on `type`.
  external TfLitePtrUnion data;

  /// A pointer to a structure representing the dimensionality interpretation
  /// that the buffer should have. NOTE: the product of elements of `dims`
  /// and the element datatype size should be equal to `bytes` below.
  external ffi.Pointer<TfLiteIntArray> dims;

  /// Quantization information.
  external TfLiteQuantizationParams params;

  /// How memory is mapped
  /// kTfLiteMmapRo: Memory mapped read only.
  /// i.e. weights
  /// kTfLiteArenaRw: Arena allocated read write memory
  /// (i.e. temporaries, outputs).
  @ffi.Int32()
  external int allocation_type;

  /// The number of bytes required to store the data of this Tensor. I.e.
  /// (bytes of each element) * dims[0] * ... * dims[n-1].  For example, if
  /// type is kTfLiteFloat32 and dims = {3, 2} then
  /// bytes = sizeof(float) * 3 * 2 = 4 * 3 * 2 = 24.
  @ffi.Size()
  external int bytes;

  /// An opaque pointer to a tflite::MMapAllocation
  external ffi.Pointer<ffi.Void> allocation;

  /// Null-terminated name of this tensor.
  external ffi.Pointer<ffi.Char> name;

  /// The delegate which knows how to handle `buffer_handle`.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteDelegate> delegate;

  /// An integer buffer handle that can be handled by `delegate`.
  /// The value is valid only when delegate is not null.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  @TfLiteBufferHandle()
  external int buffer_handle;

  /// If the delegate uses its own buffer (e.g. GPU memory), the delegate is
  /// responsible to set data_is_stale to true.
  /// `delegate->CopyFromBufferHandle` can be called to copy the data from
  /// delegate buffer.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  @ffi.Bool()
  external bool data_is_stale;

  /// True if the tensor is a variable.
  @ffi.Bool()
  external bool is_variable;

  /// Quantization information. Replaces params field above.
  external TfLiteQuantization quantization;

  /// Parameters used to encode a sparse tensor.
  /// This is optional. The field is NULL if a tensor is dense.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteSparsity> sparsity;

  /// Optional. Encodes shapes with unknown dimensions with -1. This field is
  /// only populated when unknown dimensions exist in a read-write tensor (i.e.
  /// an input or output tensor). (e.g.  `dims` contains [1, 1, 1, 3] and
  /// `dims_signature` contains [1, -1, -1, 3]).  If no unknown dimensions exist
  /// then `dims_signature` is either null, or set to an empty array.  Use
  /// `TfLiteTensorGetDimsSignature` to get `dims_signature` if non-empty or
  /// otherwise fallback to `dims`.  Note that this field only exists when
  /// TF_LITE_STATIC_MEMORY is not defined.
  external ffi.Pointer<TfLiteIntArray> dims_signature;
}

/// Types supported by tensor
/// LINT.IfChange
abstract class TfLiteType {
  static const int kTfLiteNoType = 0;
  static const int kTfLiteFloat32 = 1;
  static const int kTfLiteInt32 = 2;
  static const int kTfLiteUInt8 = 3;
  static const int kTfLiteInt64 = 4;
  static const int kTfLiteString = 5;
  static const int kTfLiteBool = 6;
  static const int kTfLiteInt16 = 7;
  static const int kTfLiteComplex64 = 8;
  static const int kTfLiteInt8 = 9;
  static const int kTfLiteFloat16 = 10;
  static const int kTfLiteFloat64 = 11;
  static const int kTfLiteComplex128 = 12;
  static const int kTfLiteUInt64 = 13;
  static const int kTfLiteResource = 14;
  static const int kTfLiteVariant = 15;
  static const int kTfLiteUInt32 = 16;
  static const int kTfLiteUInt16 = 17;
  static const int kTfLiteInt4 = 18;
  static const int kTfLiteBFloat16 = 19;
}

/// A union of pointers that points to memory for a given tensor.
///
/// Do not access these members directly, if possible, use
/// `GetTensorData<TYPE>(tensor)` instead, otherwise only access `.data`, as
/// other members are deprecated.
final class TfLitePtrUnion extends ffi.Union {
  external ffi.Pointer<ffi.Int32> i32;

  external ffi.Pointer<ffi.Uint32> u32;

  external ffi.Pointer<ffi.Int64> i64;

  external ffi.Pointer<ffi.Uint64> u64;

  external ffi.Pointer<ffi.Float> f;

  external ffi.Pointer<TfLiteFloat16> f16;

  external ffi.Pointer<TfLiteBFloat16> bf16;

  external ffi.Pointer<ffi.Double> f64;

  external ffi.Pointer<ffi.Char> raw;

  external ffi.Pointer<ffi.Char> raw_const;

  external ffi.Pointer<ffi.Uint8> uint8;

  external ffi.Pointer<ffi.Bool> b;

  external ffi.Pointer<ffi.Int16> i16;

  external ffi.Pointer<ffi.Uint16> ui16;

  external ffi.Pointer<TfLiteComplex64> c64;

  external ffi.Pointer<TfLiteComplex128> c128;

  external ffi.Pointer<ffi.Int8> int8;

  /// Only use this member.
  external ffi.Pointer<ffi.Void> data;
}

/// Half precision data type compatible with the C99 definition.
final class TfLiteFloat16 extends ffi.Struct {
  @ffi.Uint16()
  external int data;
}

/// bfloat16 data type compatible with the Google Brain definition.
/// https://cloud.google.com/tpu/docs/bfloat16.
/// This provides 1 bit of sign, 8 bits of exponent, and 7 bits of mantissa.
final class TfLiteBFloat16 extends ffi.Struct {
  @ffi.Uint16()
  external int data;
}

/// Single-precision complex data type compatible with the C99 definition.
final class TfLiteComplex64 extends ffi.Struct {
  @ffi.Float()
  external double re;

  @ffi.Float()
  external double im;
}

/// Double-precision complex data type compatible with the C99 definition.
final class TfLiteComplex128 extends ffi.Struct {
  @ffi.Double()
  external double re;

  @ffi.Double()
  external double im;
}

/// Fixed size list of integers. Used for dimensions and inputs/outputs tensor
/// indices
final class TfLiteIntArray extends ffi.Opaque {}

/// Legacy. Will be deprecated in favor of `TfLiteAffineQuantization`.
/// If per-layer quantization is specified this field will still be populated in
/// addition to `TfLiteAffineQuantization`.
/// Parameters for asymmetric quantization. Quantized values can be converted
/// back to float using: `real_value = scale * (quantized_value - zero_point)`
final class TfLiteQuantizationParams extends ffi.Struct {
  @ffi.Float()
  external double scale;

  @ffi.Int32()
  external int zero_point;
}

/// Memory allocation strategies.
/// * `kTfLiteMmapRo`: Read-only memory-mapped data, or data externally
/// allocated.
/// * `kTfLiteArenaRw`: Arena allocated with no guarantees about persistence,
/// and available during eval.
/// * `kTfLiteArenaRwPersistent`: Arena allocated but persistent across eval,
/// and only available during eval.
/// * `kTfLiteDynamic`: Allocated during eval, or for string tensors.
/// * `kTfLitePersistentRo`: Allocated and populated during prepare. This is
/// useful for tensors that can be computed during prepare and treated
/// as constant inputs for downstream ops (also in prepare).
/// * `kTfLiteCustom`: Custom memory allocation provided by the user. See
/// TfLiteCustomAllocation below.
/// * `kTfLiteVariantObject`: Allocation is an arbitrary type-erased C++
/// object.
/// Allocation and deallocation are done through `new` and `delete`.
/// * `kTfLiteNonCpu`: Tensor buffer is in non-CPU memory, such as AHWB, GPU
/// memory. This tensor is not accessed by the CPU.
/// This is only used by LiteRt API.
abstract class TfLiteAllocationType {
  static const int kTfLiteMemNone = 0;
  static const int kTfLiteMmapRo = 1;
  static const int kTfLiteArenaRw = 2;
  static const int kTfLiteArenaRwPersistent = 3;
  static const int kTfLiteDynamic = 4;
  static const int kTfLitePersistentRo = 5;
  static const int kTfLiteCustom = 6;
  static const int kTfLiteVariantObject = 7;
  static const int kTfLiteNonCpu = 8;
}

/// WARNING: This is an experimental interface that is subject to change.
final class TfLiteDelegate extends ffi.Struct {
  /// Data that delegate needs to identify itself. This data is owned by the
  /// delegate. The delegate is owned in the user code, so the delegate is
  /// responsible for deallocating this when it is destroyed.
  external ffi.Pointer<ffi.Void> data_;

  /// Invoked by `ModifyGraphWithDelegate`. This prepare is called, giving the
  /// delegate a view of the current graph through `TfLiteContext*`. It
  /// typically will look at the nodes and call
  /// `ReplaceNodeSubsetsWithDelegateKernels()` to ask the TensorFlow lite
  /// runtime to create macro-nodes to represent delegated subgraphs of the
  /// original graph.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteDelegate> delegate,
      )
    >
  >
  Prepare;

  /// Copy the data from delegate buffer handle into raw memory of the given
  /// `tensor`. Note that the delegate is allowed to allocate the raw bytes as
  /// long as it follows the rules for `kTfLiteDynamic` tensors, in which case
  /// this cannot be null.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteDelegate> delegate,
        TfLiteBufferHandle buffer_handle,
        ffi.Pointer<TfLiteTensor> tensor,
      )
    >
  >
  CopyFromBufferHandle;

  /// Copy the data from raw memory of the given `tensor` to delegate buffer
  /// handle. This can be null if the delegate doesn't use its own buffer.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteDelegate> delegate,
        TfLiteBufferHandle buffer_handle,
        ffi.Pointer<TfLiteTensor> tensor,
      )
    >
  >
  CopyToBufferHandle;

  /// Free the Delegate Buffer Handle. Note: This only frees the handle, but
  /// this doesn't release the underlying resource (e.g. textures). The
  /// resources are either owned by application layer or the delegate.
  /// This can be null if the delegate doesn't use its own buffer.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteDelegate> delegate,
        ffi.Pointer<TfLiteBufferHandle> handle,
      )
    >
  >
  FreeBufferHandle;

  /// Bitmask flags. See the comments in `TfLiteDelegateFlags`.
  @ffi.Int64()
  external int flags;

  /// The opaque delegate builder associated with this object.  If set then the
  /// TF Lite runtime will give precedence to this field.  E.g. instead of
  /// invoking `Prepare` via the function pointer inside the `TfLiteDelegate`
  /// object, the runtime will first check if the corresponding function
  /// pointer inside `opaque_delegate_builder` is set and if so invoke that.
  ///
  /// If this field is non-null, then the `Prepare` field (of the
  /// `TfLiteDelegate`) should be null.
  external ffi.Pointer<TfLiteOpaqueDelegateBuilder> opaque_delegate_builder;
}

/// `TfLiteContext` allows an op to access the tensors.
///
/// `TfLiteContext` is a struct that is created by the TF Lite runtime
/// and passed to the "methods" (C function pointers) in the
/// `TfLiteRegistration` struct that are used to define custom ops and custom
/// delegate kernels. It contains information and methods (C function pointers)
/// that can be called by the code implementing a custom op or a custom delegate
/// kernel. These methods provide access to the context in which that custom op
/// or custom delegate kernel occurs, such as access to the input and output
/// tensors for that op, as well as methods for allocating memory buffers
/// and intermediate tensors, etc.
///
/// See also `TfLiteOpaqueContext`, which is an more ABI-stable equivalent.
final class TfLiteContext extends ffi.Struct {
  /// Number of tensors in the context.
  @ffi.Size()
  external int tensors_size;

  /// The execution plan contains a list of the node indices in execution
  /// order. execution_plan->size is the current number of nodes. And,
  /// execution_plan->data[0] is the first node that needs to be run.
  /// TfLiteDelegates can traverse the current execution plan by iterating
  /// through each member of this array and using GetNodeAndRegistration() to
  /// access details about a node. i.e.
  ///
  ///
  /// TfLiteIntArray* execution_plan;
  /// TF_LITE_ENSURE_STATUS(context->GetExecutionPlan(context,
  /// &execution_plan));
  /// for (int exec_index = 0; exec_index < execution_plan->size;
  /// exec_index++) {
  /// int node_index = execution_plan->data[exec_index];
  /// TfLiteNode* node;
  /// TfLiteRegistration* reg;
  /// context->GetNodeAndRegistration(context, node_index, &node, &reg);
  /// }
  ///
  /// Note: the memory pointed by '`*execution_plan` is OWNED by TfLite runtime.
  /// Future calls to GetExecutionPlan invalidates earlier outputs. The
  /// following code snippet shows the issue of such an invocation pattern.
  /// After calling CheckNode, subsequent access to `plan_1st` is undefined.
  ///
  /// void CheckNode(const TfLiteNode* node) {
  /// ...
  /// TfLiteIntArray* plan_2nd;
  /// TF_LITE_ENSURE_STATUS(
  /// context->GetExecutionPlan(context, &plan_2nd)
  /// );
  /// ...
  /// }
  ///
  /// TfLiteIntArray* plan_1st;
  /// TF_LITE_ENSURE_STATUS(context->GetExecutionPlan(context, &plan_1st));
  /// for (int exec_index = 0; exec_index < plan_1st->size; exec_index++) {
  /// int node_index = plan_1st->data[exec_index];
  /// TfLiteNode* node;
  /// TfLiteRegistration* reg;
  /// context->GetNodeAndRegistration(context, node_index, &node, &reg);
  /// CheckNode(node);
  /// }
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Pointer<TfLiteIntArray>> execution_plan,
      )
    >
  >
  GetExecutionPlan;

  /// An array of tensors in the interpreter context (of length `tensors_size`)
  external ffi.Pointer<TfLiteTensor> tensors;

  /// opaque full context ptr (an opaque c++ data structure)
  external ffi.Pointer<ffi.Void> impl_;

  /// Request memory pointer be resized. Updates dimensions on the tensor.
  /// NOTE: ResizeTensor takes ownership of newSize.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext>,
        ffi.Pointer<TfLiteTensor>,
        ffi.Pointer<TfLiteIntArray>,
      )
    >
  >
  ResizeTensor;

  /// Request that an error be reported with format string msg.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(ffi.Pointer<TfLiteContext>, ffi.Pointer<ffi.Char>)
    >
  >
  ReportError;

  /// Add `tensors_to_add` tensors, preserving pre-existing Tensor entries.  If
  /// non-null, the value pointed to by `first_new_tensor_index` will be set to
  /// the index of the first new tensor.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext>,
        ffi.Int,
        ffi.Pointer<ffi.Int>,
      )
    >
  >
  AddTensors;

  /// Get a Tensor node by node_index.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext>,
        ffi.Int,
        ffi.Pointer<ffi.Pointer<TfLiteNode>>,
        ffi.Pointer<ffi.Pointer<TfLiteRegistration>>,
      )
    >
  >
  GetNodeAndRegistration;

  /// Replace ops with one or more stub delegate operations. This function
  /// does not take ownership of `nodes_to_replace`.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext>,
        TfLiteRegistration,
        ffi.Pointer<TfLiteIntArray>,
        ffi.Pointer<TfLiteDelegate>,
      )
    >
  >
  ReplaceNodeSubsetsWithDelegateKernels;

  /// Number of threads that are recommended to subsystems like gemmlowp and
  /// eigen.
  @ffi.Int()
  external int recommended_num_threads;

  /// Access external contexts by type.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<TfLiteExternalContext> Function(
        ffi.Pointer<TfLiteContext>,
        ffi.Int32,
      )
    >
  >
  GetExternalContext;

  /// Set the value of a external context. Does not take ownership of the
  /// pointer.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext>,
        ffi.Int32,
        ffi.Pointer<TfLiteExternalContext>,
      )
    >
  >
  SetExternalContext;

  /// Flag for allowing float16 precision for FP32 calculation.
  /// default: false.
  ///
  /// WARNING: This is an experimental API and subject to change.
  @ffi.Bool()
  external bool allow_fp32_relax_to_fp16;

  /// Pointer to the op-level profiler, if set; nullptr otherwise.
  external ffi.Pointer<ffi.Void> profiler;

  /// Allocate persistent buffer which has the same life time as the
  /// interpreter. Returns `nullptr` on failure. The memory is allocated from
  /// heap for TFL, and from tail in TFLM. This method is only available in
  /// `Init` or `Prepare` stage.
  ///
  /// WARNING: This is an experimental interface that is subject
  /// to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> ctx,
        ffi.Size bytes,
      )
    >
  >
  AllocatePersistentBuffer;

  /// Allocate a buffer which will be deallocated right after invoke phase.
  /// The memory is allocated from heap in TFL, and from volatile arena in TFLM.
  /// This method is only available in invoke stage.
  ///
  /// NOTE: If possible use `RequestScratchBufferInArena` method to avoid memory
  /// allocation during inference time.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> ctx,
        ffi.Size bytes,
        ffi.Pointer<ffi.Pointer<ffi.Void>> ptr,
      )
    >
  >
  AllocateBufferForEval;

  /// Request a scratch buffer in the arena through static memory planning.
  /// This method is only available in `Prepare` stage and the buffer is
  /// allocated by the interpreter between Prepare and Eval stage. In `Eval`
  /// stage, `GetScratchBuffer` API can be used to fetch the address.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> ctx,
        ffi.Size bytes,
        ffi.Pointer<ffi.Int> buffer_idx,
      )
    >
  >
  RequestScratchBufferInArena;

  /// Get the scratch buffer pointer.
  /// This method is only available in Eval stage.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> ctx,
        ffi.Int buffer_idx,
      )
    >
  >
  GetScratchBuffer;

  /// Resize the memory pointer of the `tensor`. This method behaves the same as
  /// `ResizeTensor`, except that it makes a copy of the shape array internally
  /// so the shape array could be deallocated right afterwards.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> ctx,
        ffi.Pointer<TfLiteTensor> tensor,
        ffi.Int dims,
        ffi.Pointer<ffi.Int> shape,
      )
    >
  >
  ResizeTensorExplicit;

  /// This method provides a preview of post-delegation partitioning. Each
  /// TfLiteDelegateParams in the referenced array corresponds to one instance
  /// of the delegate kernel. Example usage:
  ///
  /// TfLiteIntArray* nodes_to_replace = ...;
  /// TfLiteDelegateParams* params_array;
  /// int num_partitions = 0;
  /// TF_LITE_ENSURE_STATUS(context->PreviewDelegatePartitioning(
  /// context, delegate, nodes_to_replace, &params_array,
  /// &num_partitions));
  /// for (int idx = 0; idx < num_partitions; idx++) {
  /// const auto& partition_params = params_array[idx];
  /// ...
  /// }
  ///
  /// NOTE: The context owns the memory referenced by partition_params_array. It
  /// will be cleared with another call to PreviewDelegatePartitioning, or after
  /// TfLiteDelegateParams::Prepare returns.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteIntArray> nodes_to_replace,
        ffi.Pointer<ffi.Pointer<TfLiteDelegateParams>> partition_params_array,
        ffi.Pointer<ffi.Int> num_partitions,
      )
    >
  >
  PreviewDelegatePartitioning;

  /// Returns a TfLiteTensor struct for a given index.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  ///
  /// WARNING: This method may not be available on all platforms.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<TfLiteTensor> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Int tensor_idx,
      )
    >
  >
  GetTensor;

  /// Returns a TfLiteEvalTensor struct for a given index.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  ///
  /// WARNING: This method may not be available on all platforms.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<TfLiteEvalTensor> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Int tensor_idx,
      )
    >
  >
  GetEvalTensor;

  /// Retrieves named metadata buffer from the TFLite model.
  /// Returns kTfLiteOk if metadata is successfully obtained from the flatbuffer
  /// Model: that is, there exists a `metadata` entry with given `name` string.
  /// (see TFLite's schema.fbs).
  /// The corresponding `buffer` information is populated in `ptr` & `bytes`.
  /// The data from `ptr` is valid for the lifetime of the Interpreter.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Char> name,
        ffi.Pointer<ffi.Pointer<ffi.Char>> ptr,
        ffi.Pointer<ffi.Size> bytes,
      )
    >
  >
  GetModelMetadata;

  /// Retrieves the corresponding TfLiteContext of a subgraph that the given
  /// subgraph_index points to and switches to the delegate context for that
  /// subgraph. If an invalid subgraph index is given, returns kTfLiteError.
  ///
  /// NOTE: This function is expected to be paired with ReleaseSubgraphContext()
  /// once the delegate preparation is done and/or the delegate context
  /// functions are no longer needed.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Int subgraph_index,
        ffi.Pointer<ffi.Pointer<TfLiteContext>> acquired_context,
      )
    >
  >
  AcquireSubgraphContext;

  /// Releases the subgraph context by switching back to the TFLite kernel
  /// context for the subgraph that the given subgraph_index points to.
  ///
  /// NOTE: This function is expected to be used after AcquireSubgraphContext()
  /// once the delegate preparation is done and/or the delegate context
  /// functions are no longer needed.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Int subgraph_index,
      )
    >
  >
  ReleaseSubgraphContext;
}

/// A structure representing an instance of a node.
/// This structure only exhibits the inputs, outputs, user defined data and some
/// node properties (like statefulness), not other features like the type.
final class TfLiteNode extends ffi.Struct {
  /// Inputs to this node expressed as indices into the simulator's tensors.
  external ffi.Pointer<TfLiteIntArray> inputs;

  /// Outputs to this node expressed as indices into the simulator's tensors.
  external ffi.Pointer<TfLiteIntArray> outputs;

  /// intermediate tensors to this node expressed as indices into the
  /// simulator's tensors.
  external ffi.Pointer<TfLiteIntArray> intermediates;

  /// Temporary tensors uses during the computations. This usually contains no
  /// tensors, but ops are allowed to change that if they need scratch space of
  /// any sort.
  external ffi.Pointer<TfLiteIntArray> temporaries;

  /// Opaque data provided by the node implementer through `Registration.init`.
  external ffi.Pointer<ffi.Void> user_data;

  /// Opaque data provided to the node if the node is a builtin. This is usually
  /// a structure defined in builtin_op_data.h
  external ffi.Pointer<ffi.Void> builtin_data;

  /// Custom initial data. This is the opaque data provided in the flatbuffer.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<ffi.Void> custom_initial_data;

  @ffi.Int()
  external int custom_initial_data_size;

  /// The pointer to the delegate. This is non-null only when the node is
  /// created by calling `interpreter.ModifyGraphWithDelegate`.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<TfLiteDelegate> delegate;

  /// Whether this op might have side effect (e.g. stateful op).
  @ffi.Bool()
  external bool might_have_side_effect;
}

/// `TfLiteRegistration` defines the implementation of an operation
/// (a built-in op, custom op, or custom delegate kernel).
///
/// It is a struct containing "methods" (C function pointers) that will be
/// invoked by the TF Lite runtime to evaluate instances of the operation.
///
/// See also `TfLiteOperator` which is a more ABI-stable equivalent.
final class TfLiteRegistration extends ffi.Struct {
  /// Initializes the op from serialized data.
  /// Called only *once* for the lifetime of the op, so any one-time allocations
  /// should be made here (unless they depend on tensor sizes).
  ///
  /// * If a built-in op:
  /// * `buffer` is the op's params data (TfLiteLSTMParams*).
  /// * `length` is zero.
  /// * If custom op:
  /// * `buffer` is the op's `custom_options`.
  /// * `length` is the size of the buffer.
  ///
  /// Returns a type-punned (i.e. void*) opaque data (e.g. a primitive pointer
  /// or an instance of a struct).
  ///
  /// The returned pointer will be stored with the node in the `user_data`
  /// field, accessible within prepare and invoke functions below.
  ///
  /// NOTE: if the data is already in the desired format, simply implement this
  /// function to return `nullptr` and implement the free function to be a
  /// no-op.
  ///
  /// NOTE: For a Delegate kernel, returns `TfLiteKernelInitFailed()` if it
  /// fails on the initialization. This eventually causes user's API call to
  /// InterpreterBuilder::operator() or Interpreter::ModifyGraphWithDelegate()
  /// to return an error.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Char> buffer,
        ffi.Size length,
      )
    >
  >
  init;

  /// The pointer `buffer` is the data previously returned by an init
  /// invocation.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Void> buffer,
      )
    >
  >
  free;

  /// prepare is called when the inputs this node depends on have been resized.
  /// `context->ResizeTensor()` can be called to request output tensors to be
  /// resized.
  /// Can be called multiple times for the lifetime of the op.
  ///
  /// Returns `kTfLiteOk` on success.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  prepare;

  /// Execute the node (should read `node->inputs` and output to
  /// `node->outputs`).
  ///
  /// Returns `kTfLiteOk` on success.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  invoke;

  /// `profiling_string` is called during summarization of profiling information
  /// in order to group executions together. Providing a value here will cause a
  /// given op to appear multiple times is the profiling report. This is
  /// particularly useful for custom ops that can perform significantly
  /// different calculations depending on their `user-data`.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  profiling_string;

  /// Builtin codes. If this kernel refers to a builtin this is the code
  /// of the builtin. This is so we can do marshaling to other frameworks like
  /// NN API.
  ///
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  @ffi.Int32()
  external int builtin_code;

  /// Custom op name. If the op is a builtin, this will be `null`.
  ///
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  ///
  /// WARNING: This is an experimental interface that is subject to change.
  external ffi.Pointer<ffi.Char> custom_name;

  /// The version of the op.
  /// Note: It is the responsibility of the registration binder to set this
  /// properly.
  @ffi.Int()
  external int version;

  /// The external (i.e. ABI-stable) version of `TfLiteRegistration`.
  /// Since we can't use internal types (such as `TfLiteContext`) for C API to
  /// maintain ABI stability.  C API user will provide `TfLiteOperator` to
  /// implement custom ops.  We keep it inside of `TfLiteRegistration` and use
  /// it to route callbacks properly.
  external ffi.Pointer<TfLiteOperator> registration_external;

  /// Retrieves asynchronous kernel.
  ///
  /// If the `async_kernel` field is nullptr, it means the operation described
  /// by this TfLiteRegistration object does not support asynchronous execution.
  /// Otherwise, the function that the field points to should only be called for
  /// delegate kernel nodes, i.e. `node` should be a delegate kernel node
  /// created by applying a delegate. If the function returns nullptr, that
  /// means that the underlying delegate does not support asynchronous execution
  /// for this `node`.
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<TfLiteAsyncKernel> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  async_kernel;

  /// Indicates if an operator's output may safely overwrite its inputs.
  /// See the comments in `TfLiteInPlaceOp`.
  @ffi.Uint64()
  external int inplace_operator;
}

/// An external context is a collection of information unrelated to the TF Lite
/// framework, but useful to a subset of the ops. TF Lite knows very little
/// about the actual contexts, but it keeps a list of them, and is able to
/// refresh them if configurations like the number of recommended threads
/// change.
final class TfLiteExternalContext extends ffi.Struct {
  @ffi.Int32()
  external int type;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<TfLiteContext> context)>
  >
  Refresh;
}

/// The list of external context types known to TF Lite. This list exists solely
/// to avoid conflicts and to ensure ops can share the external contexts they
/// need. Access to the external contexts is controlled by one of the
/// corresponding support files.
abstract class TfLiteExternalContextType {
  static const int kTfLiteEigenContext = 0;

  /// include eigen_support.h to use.
  static const int kTfLiteGemmLowpContext = 1;

  /// include gemm_support.h to use.
  static const int kTfLiteEdgeTpuContext = 2;

  /// Placeholder for Edge TPU support.
  static const int kTfLiteCpuBackendContext = 3;

  /// include cpu_backend_context.h to use.
  static const int kTfLiteLiteRtBufferContext = 4;

  /// include external_litert_buffer_context.h to use.
  static const int kTfLiteMaxExternalContexts = 5;
}

/// WARNING: This is an experimental interface that is subject to change.
///
/// Currently, TfLiteDelegateParams has to be allocated in a way that it's
/// trivially destructable. It will be stored as `builtin_data` field in
/// `TfLiteNode` of the delegate node.
///
/// See also the `CreateDelegateParams` function in `interpreter.cc` details.
final class TfLiteDelegateParams extends ffi.Struct {
  external ffi.Pointer<TfLiteDelegate> delegate;

  external ffi.Pointer<TfLiteIntArray> nodes_to_replace;

  external ffi.Pointer<TfLiteIntArray> input_tensors;

  external ffi.Pointer<TfLiteIntArray> output_tensors;
}

/// Light-weight tensor struct for TF Micro runtime. Provides the minimal amount
/// of information required for a kernel to run during TfLiteRegistration::Eval.
/// TODO(b/160955687): Move this field into TF_LITE_STATIC_MEMORY when TFLM
/// builds with this flag by default internally.
final class TfLiteEvalTensor extends ffi.Struct {
  /// A union of data pointers. The appropriate type should be used for a typed
  /// tensor based on `type`.
  external TfLitePtrUnion data;

  /// A pointer to a structure representing the dimensionality interpretation
  /// that the buffer should have.
  external ffi.Pointer<TfLiteIntArray> dims;

  /// The data type specification for data stored in `data`. This affects
  /// what member of `data` union should be used.
  @ffi.Int32()
  external int type;
}

/// The delegates should use zero or positive integers to represent handles.
/// -1 is reserved from unallocated status.
typedef TfLiteBufferHandle = ffi.Int;
typedef DartTfLiteBufferHandle = int;

/// `TfLiteOpaqueDelegateBuilder` is used for constructing
/// `TfLiteOpaqueDelegate`, see `TfLiteOpaqueDelegateCreate` in c_api_opaque.h.
/// NOTE: This struct is not ABI stable.
///
/// For forward source compatibility `TfLiteOpaqueDelegateBuilder` objects
/// should be brace-initialized, so that all fields (including any that might be
/// added in the future) get zero-initialized.  The purpose of each field is
/// exactly the same as with `TfLiteDelegate`.
///
/// NOTE: This type is part of the TensorFlow Lite Extension APIs.
/// We reserve the right to make changes to this API in future releases,
/// potentially including non-backwards-compatible changes, on a different
/// schedule than for the other TensorFlow Lite APIs. See
/// https://www.tensorflow.org/guide/versions#separate_version_number_for_tensorflow_lite_extension_apis.
final class TfLiteOpaqueDelegateBuilder extends ffi.Struct {
  /// Data that delegate needs to identify itself. This data is owned by the
  /// delegate. The delegate is owned in the user code, so the delegate is
  /// responsible for deallocating this when it is destroyed.
  external ffi.Pointer<ffi.Void> data;

  /// NOLINT
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteOpaqueContext> context,
        ffi.Pointer<TfLiteOpaqueDelegate> delegate,
        ffi.Pointer<ffi.Void> data,
      )
    >
  >
  Prepare;

  /// NOLINT
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteOpaqueContext> context,
        ffi.Pointer<TfLiteOpaqueDelegate> delegate,
        ffi.Pointer<ffi.Void> data,
        TfLiteBufferHandle buffer_handle,
        ffi.Pointer<TfLiteOpaqueTensor> tensor,
      )
    >
  >
  CopyFromBufferHandle;

  /// NOLINT
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteOpaqueContext> context,
        ffi.Pointer<TfLiteOpaqueDelegate> delegate,
        ffi.Pointer<ffi.Void> data,
        TfLiteBufferHandle buffer_handle,
        ffi.Pointer<TfLiteOpaqueTensor> tensor,
      )
    >
  >
  CopyToBufferHandle;

  /// NOLINT
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteOpaqueContext> context,
        ffi.Pointer<TfLiteOpaqueDelegate> delegate,
        ffi.Pointer<ffi.Void> data,
        ffi.Pointer<TfLiteBufferHandle> handle,
      )
    >
  >
  FreeBufferHandle;

  /// Bitmask flags. See the comments in `TfLiteDelegateFlags`.
  @ffi.Int64()
  external int flags;
}

typedef TfLiteOpaqueDelegate = TfLiteDelegate;

final class TfLiteOpaqueTensor extends ffi.Opaque {}

/// Structure specifying the quantization used by the tensor, if-any.
final class TfLiteQuantization extends ffi.Struct {
  /// The type of quantization held by params.
  @ffi.Int32()
  external int type;

  /// Holds an optional reference to a quantization param structure. The actual
  /// type depends on the value of the `type` field (see the comment there for
  /// the values and corresponding types).
  external ffi.Pointer<ffi.Void> params;
}

abstract class TfLiteQuantizationType {
  /// No quantization.
  static const int kTfLiteNoQuantization = 0;

  /// Affine quantization (with support for per-channel quantization).
  /// Corresponds to TfLiteAffineQuantization.
  static const int kTfLiteAffineQuantization = 1;

  /// Blockwise quantization.
  static const int kTfLiteBlockwiseQuantization = 2;
}

/// Parameters used to encode a sparse tensor. For detailed explanation of each
/// field please refer to lite/schema/schema.fbs.
final class TfLiteSparsity extends ffi.Struct {
  external ffi.Pointer<TfLiteIntArray> traversal_order;

  external ffi.Pointer<TfLiteIntArray> block_map;

  external ffi.Pointer<TfLiteDimensionMetadata> dim_metadata;

  @ffi.Int()
  external int dim_metadata_size;
}

/// Metadata to encode each dimension in a sparse tensor.
final class TfLiteDimensionMetadata extends ffi.Struct {
  @ffi.Int32()
  external int format;

  @ffi.Int()
  external int dense_size;

  external ffi.Pointer<TfLiteIntArray> array_segments;

  external ffi.Pointer<TfLiteIntArray> array_indices;
}

/// Storage format of each dimension in a sparse tensor.
abstract class TfLiteDimensionType {
  static const int kTfLiteDimDense = 0;
  static const int kTfLiteDimSparseCSR = 1;
}

final class TfLiteSignatureRunner extends ffi.Opaque {}

typedef va_list = __builtin_va_list;
typedef __builtin_va_list = ffi.Pointer<ffi.Char>;

/// \private
/// Old version of `TfLiteRegistration` to maintain binary backward
/// compatibility.
/// The legacy registration type must be a POD struct type whose field types
/// must be a prefix of the field types in TfLiteRegistration, and offset of the
/// first field in TfLiteRegistration that is not present in the legacy
/// registration type must be greater than or equal to the size of the legacy
/// registration type.
///
/// WARNING: This structure is deprecated / not an official part of the
/// API. It should be only used for binary backward compatibility.
final class TfLiteRegistration_V3 extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Char> buffer,
        ffi.Size length,
      )
    >
  >
  init;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Void> buffer,
      )
    >
  >
  free;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  prepare;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  invoke;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  profiling_string;

  @ffi.Int32()
  external int builtin_code;

  external ffi.Pointer<ffi.Char> custom_name;

  @ffi.Int()
  external int version;

  external ffi.Pointer<TfLiteOperator> registration_external;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<TfLiteAsyncKernel> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  async_kernel;
}

/// \private
/// Old version of `TfLiteRegistration` to maintain binary backward
/// compatibility.
/// The legacy registration type must be a POD struct type whose field types
/// must be a prefix of the field types in TfLiteRegistration, and offset of the
/// first field in TfLiteRegistration that is not present in the legacy
/// registration type must be greater than or equal to the size of the legacy
/// registration type.
///
/// WARNING: This structure is deprecated / not an official part of the
/// API. It should be only used for binary backward compatibility.
final class TfLiteRegistration_V2 extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Char> buffer,
        ffi.Size length,
      )
    >
  >
  init;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Void> buffer,
      )
    >
  >
  free;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  prepare;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  invoke;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  profiling_string;

  @ffi.Int32()
  external int builtin_code;

  external ffi.Pointer<ffi.Char> custom_name;

  @ffi.Int()
  external int version;

  external ffi.Pointer<TfLiteOperator> registration_external;
}

/// \private
/// Old version of `TfLiteRegistration` to maintain binary backward
/// compatibility.
/// The legacy registration type must be a POD struct type whose field types
/// must be a prefix of the field types in TfLiteRegistration, and offset of the
/// first field in TfLiteRegistration that is not present in the legacy
/// registration type must be greater than or equal to the size of the legacy
/// registration type.
///
/// WARNING: This structure is deprecated / not an official part of the
/// API. It should be only used for binary backward compatibility.
final class TfLiteRegistration_V1 extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Void> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Char> buffer,
        ffi.Size length,
      )
    >
  >
  init;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<ffi.Void> buffer,
      )
    >
  >
  free;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  prepare;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Int32 Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  invoke;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(
        ffi.Pointer<TfLiteContext> context,
        ffi.Pointer<TfLiteNode> node,
      )
    >
  >
  profiling_string;

  @ffi.Int32()
  external int builtin_code;

  external ffi.Pointer<ffi.Char> custom_name;

  @ffi.Int()
  external int version;
}

/// Defines a custom memory allocation not owned by the runtime.
/// `data` should be aligned to kDefaultTensorAlignment defined in
/// lite/util.h. (Currently 64 bytes)
/// NOTE: See `Interpreter::SetCustomAllocationForTensor` for details on usage.
final class TfLiteCustomAllocation extends ffi.Struct {
  external ffi.Pointer<ffi.Void> data;

  @ffi.Size()
  external int bytes;
}

/// Forward declaration, to avoid need for dependency on
/// tensorflow/lite/profiling/telemetry/profiler.h.
final class TfLiteTelemetryProfilerStruct extends ffi.Opaque {}

abstract class TfLiteCoreMlDelegateEnabledDevices {
  /// Create Core ML delegate only on devices with Apple Neural Engine.
  /// Returns nullptr otherwise.
  static const int TfLiteCoreMlDelegateDevicesWithNeuralEngine = 0;

  /// Always create Core ML delegate
  static const int TfLiteCoreMlDelegateAllDevices = 1;
}

final class TfLiteCoreMlDelegateOptions extends ffi.Struct {
  /// Only create delegate when Neural Engine is available on the device.
  @ffi.Int32()
  external int enabled_devices;

  /// Specifies target Core ML version for model conversion.
  /// Core ML 3 come with a lot more ops, but some ops (e.g. reshape) is not
  /// delegated due to input rank constraint.
  /// if not set to one of the valid versions, the delegate will use highest
  /// version possible in the platform.
  /// Valid versions: (2, 3)
  @ffi.Int()
  external int coreml_version;

  /// This sets the maximum number of Core ML delegates created.
  /// Each graph corresponds to one delegated node subset in the
  /// TFLite model. Set this to 0 to delegate all possible partitions.
  @ffi.Int()
  external int max_delegated_partitions;

  /// This sets the minimum number of nodes per partition delegated with
  /// Core ML delegate. Defaults to 2.
  @ffi.Int()
  external int min_nodes_per_partition;
}

abstract class TFLGpuDelegateWaitType {
  /// waitUntilCompleted
  static const int TFLGpuDelegateWaitTypePassive = 0;

  /// Minimize latency. It uses active spinning instead of mutex and consumes
  /// additional CPU resources.
  static const int TFLGpuDelegateWaitTypeActive = 1;

  /// Useful when the output is used with GPU pipeline then or if external
  /// command encoder is set.
  static const int TFLGpuDelegateWaitTypeDoNotWait = 2;

  /// Tries to avoid GPU sleep mode.
  static const int TFLGpuDelegateWaitTypeAggressive = 3;
}

/// Creates a new delegate instance that need to be destroyed with
/// DeleteFlowDelegate when delegate is no longer used by tflite.
final class TFLGpuDelegateOptions extends ffi.Struct {
  /// Allows to quantify tensors, downcast values, process in float16 etc.
  @ffi.Bool()
  external bool allow_precision_loss;

  @ffi.Int32()
  external int wait_type;

  /// Allows execution of integer quantized models
  @ffi.Bool()
  external bool enable_quantization;
}

final class TfLiteXNNPackDelegateWeightsCache extends ffi.Opaque {}

final class TfLiteXNNPackDelegateOptions extends ffi.Struct {
  /// Number of threads to use in the thread pool.
  /// 0 or negative value means no thread pool used.
  @ffi.Int32()
  external int num_threads;

  /// Flags to pass to `xnn_create_runtime`
  @ffi.Uint32()
  external int runtime_flags;

  /// Bitfield with any combination of the following binary options:
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_QS8
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_QU8
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_DYNAMIC_FULLY_CONNECTED
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_VARIABLE_OPERATORS
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_TRANSIENT_INDIRECTION_BUFFER
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_ENABLE_LATEST_OPERATORS
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_ENABLE_SUBGRAPH_RESHAPING
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_DISABLE_SUBGRAPH_RESHAPING
  /// - TFLITE_XNNPACK_DELEGATE_FLAG_SLOW_CONSISTENT_ARITHMETIC
  @ffi.Uint32()
  external int flags;

  /// Cache for packed weights, can be shared between multiple instances of
  /// delegates.
  external ffi.Pointer<TfLiteXNNPackDelegateWeightsCache> weights_cache;

  /// Deprecated. Use the flags bitfield with the
  /// TFLITE_XNNPACK_DELEGATE_FLAG_VARIABLE_OPERATORS mask.
  @ffi.Bool()
  external bool handle_variable_ops;

  /// Path to the weight cache to load.
  ///
  /// Note: To keep backwards compatibility with the previous caching mechanism,
  /// the weight cache will only be loaded from this if `weights_cache` is
  /// undefined.
  external ffi.Pointer<ffi.Char> weight_cache_file_path;

  /// Explicit file descriptor for the weight cache.
  ///
  /// Warning: This will override opening the file from `weight_cache_file_path`.
  ///
  /// Warning: Because value initialization of a C structure will initialize this
  /// field to 0, we cannot accept a file descriptor with that value to remain
  /// compatible with existing code. Hopefully this won't cause issues as the
  /// file descriptor 0 is usually a special one.
  ///
  /// Warning: Ownership of the file descriptor is taken by the XNNPack delegate
  /// weight cache. `dup` it if you want to keep it open for longer.
  ///
  /// Note: To keep backwards compatibility with the previous caching mechanism,
  /// the weight cache will only be loaded from this if `weights_cache` is
  /// undefined.
  @ffi.Int()
  external int weight_cache_file_descriptor;

  /// Points to an existing instance of a weight cache provider.
  ///
  /// Warning: Ownership of the cache provider is **NOT** taken by the XNNPack
  /// delegate.
  ///
  /// Warning: This will override opening the file from `weight_cache_file_path`
  /// and `weight_cache_file_descriptor`.
  ///
  /// Note: To keep backwards compatibility with the previous caching mechanism,
  /// the weight cache will only be loaded from this if `weights_cache` is
  /// undefined.
  external ffi.Pointer<ffi.Void> weight_cache_provider;
}

/// Encapsulated compilation/runtime tradeoffs.
abstract class TfLiteGpuInferenceUsage {
  /// Delegate will be used only once, therefore, bootstrap/init time should
  /// be taken into account.
  static const int TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER = 0;

  /// Prefer maximizing the throughput. Same delegate will be used repeatedly on
  /// multiple inputs.
  static const int TFLITE_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED = 1;

  /// Balance init latency and throughput. This option will result in slightly
  /// higher init latency than FAST_SINGLE_ANSWER but should have inference
  /// latency closer to SUSTAINED_SPEED.
  static const int TFLITE_GPU_INFERENCE_PREFERENCE_BALANCED = 2;
}

abstract class TfLiteGpuInferencePriority {
  /// AUTO priority is needed when a single priority is the most important
  /// factor. For example,
  /// priority1 = MIN_LATENCY would result in the configuration that achieves
  /// maximum performance.
  static const int TFLITE_GPU_INFERENCE_PRIORITY_AUTO = 0;
  static const int TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION = 1;
  static const int TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY = 2;
  static const int TFLITE_GPU_INFERENCE_PRIORITY_MIN_MEMORY_USAGE = 3;
}

/// Used to toggle experimental flags used in the delegate. Note that this is a
/// bitmask, so the values should be 1, 2, 4, 8, ...etc.
abstract class TfLiteGpuExperimentalFlags {
  static const int TFLITE_GPU_EXPERIMENTAL_FLAGS_NONE = 0;

  /// Enables inference on quantized models with the delegate.
  /// NOTE: This is enabled in TfLiteGpuDelegateOptionsV2Default.
  static const int TFLITE_GPU_EXPERIMENTAL_FLAGS_ENABLE_QUANT = 1;

  /// Enforces execution with the provided backend.
  static const int TFLITE_GPU_EXPERIMENTAL_FLAGS_CL_ONLY = 2;
  static const int TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY = 4;

  /// Enable serialization of GPU kernels & model data. Speeds up initialization
  /// at the cost of space on disk.
  /// Delegate performs serialization the first time it is applied with a new
  /// model or inference params. Later initializations are fast.
  /// ModifyGraphWithDelegate will fail if data cannot be serialized.
  ///
  /// NOTE: User also needs to set serialization_dir & model_token in
  /// TfLiteGpuDelegateOptionsV2.
  /// Currently works only if CL backend is used.
  static const int TFLITE_GPU_EXPERIMENTAL_FLAGS_ENABLE_SERIALIZATION = 8;
}

/// IMPORTANT: Always use TfLiteGpuDelegateOptionsV2Default() method to create
/// new instance of TfLiteGpuDelegateOptionsV2, otherwise every new added option
/// may break inference.
final class TfLiteGpuDelegateOptionsV2 extends ffi.Struct {
  /// When set to zero, computations are carried out in maximal possible
  /// precision. Otherwise, the GPU may quantify tensors, downcast values,
  /// process in FP16 to increase performance. For most models precision loss is
  /// warranted.
  /// [OBSOLETE]: to be removed
  @ffi.Int32()
  external int is_precision_loss_allowed;

  /// Preference is defined in TfLiteGpuInferenceUsage.
  @ffi.Int32()
  external int inference_preference;

  /// Ordered priorities provide better control over desired semantics,
  /// where priority(n) is more important than priority(n+1), therefore,
  /// each time inference engine needs to make a decision, it uses
  /// ordered priorities to do so.
  /// For example:
  /// MAX_PRECISION at priority1 would not allow to decrease precision,
  /// but moving it to priority2 or priority3 would result in F16 calculation.
  ///
  /// Priority is defined in TfLiteGpuInferencePriority.
  /// AUTO priority can only be used when higher priorities are fully specified.
  /// For example:
  /// VALID:   priority1 = MIN_LATENCY, priority2 = AUTO, priority3 = AUTO
  /// VALID:   priority1 = MIN_LATENCY, priority2 = MAX_PRECISION,
  /// priority3 = AUTO
  /// INVALID: priority1 = AUTO, priority2 = MIN_LATENCY, priority3 = AUTO
  /// INVALID: priority1 = MIN_LATENCY, priority2 = AUTO,
  /// priority3 = MAX_PRECISION
  /// Invalid priorities will result in error.
  @ffi.Int32()
  external int inference_priority1;

  @ffi.Int32()
  external int inference_priority2;

  @ffi.Int32()
  external int inference_priority3;

  /// Bitmask flags. See the comments in TfLiteGpuExperimentalFlags.
  @ffi.Int64()
  external int experimental_flags;

  /// A graph could have multiple partitions that can be delegated to the GPU.
  /// This limits the maximum number of partitions to be delegated. By default,
  /// it's set to 1 in TfLiteGpuDelegateOptionsV2Default().
  @ffi.Int32()
  external int max_delegated_partitions;

  /// The nul-terminated directory to use for serialization.
  /// Whether serialization actually happens or not is dependent on backend used
  /// and validity of this directory.
  /// Set to nullptr in TfLiteGpuDelegateOptionsV2Default(), which implies the
  /// delegate will not try serialization.
  ///
  /// NOTE: Users should ensure that this directory is private to the app to
  /// avoid data access issues.
  external ffi.Pointer<ffi.Char> serialization_dir;

  /// The unique nul-terminated token string that acts as a 'namespace' for
  /// all serialization entries.
  /// Should be unique to a particular model (graph & constants).
  /// For an example of how to generate this from a TFLite model, see
  /// StrFingerprint() in lite/delegates/serialization.h.
  ///
  /// Set to nullptr in TfLiteGpuDelegateOptionsV2Default(), which implies the
  /// delegate will not try serialization.
  external ffi.Pointer<ffi.Char> model_token;
}

const int TFLITE_XNNPACK_DELEGATE_FLAG_QS8 = 1;

const int TFLITE_XNNPACK_DELEGATE_FLAG_QU8 = 2;

const int TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16 = 4;

const int TFLITE_XNNPACK_DELEGATE_FLAG_DYNAMIC_FULLY_CONNECTED = 8;

const int TFLITE_XNNPACK_DELEGATE_FLAG_VARIABLE_OPERATORS = 16;

const int TFLITE_XNNPACK_DELEGATE_FLAG_TRANSIENT_INDIRECTION_BUFFER = 32;

const int TFLITE_XNNPACK_DELEGATE_FLAG_ENABLE_LATEST_OPERATORS = 64;

const int TFLITE_XNNPACK_DELEGATE_FLAG_ENABLE_SUBGRAPH_RESHAPING = 128;

const int TFLITE_XNNPACK_DELEGATE_FLAG_SLOW_CONSISTENT_ARITHMETIC = 512;

const int TFLITE_XNNPACK_DELEGATE_FLAG_DISABLE_SUBGRAPH_RESHAPING = 1024;
